{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>จุดจุดจุด อ่ะก่อนอื่น คนเรือง เลือดสำคัญต่อก็ค...</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ก็ได้เสียงประมาณนั้นคล้ายคล้ายกับแคลคูลัสใช่ไห...</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>แม้ว่าโจทย์เราจะทำโจทย์ทุกอันให้มีความจริงอยู่...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ซิทีฟ เป็น office ไม่ใช่ media ฟังก์ชัน นะครับ...</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>สมการนี้ เอ๊ะเราจะหายังไงดี ถ้ามองเป็นมุมมองขอ...</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>บิลโอเค ก่อนโยกครั้นถัดไปครับ ไม่ได้นะครับในบา...</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>ไปอัพเดทท็อปในการเลือก ไปอัพเดทในการเลือกอัพเด...</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>นะครับแต่สิ่งที่ผมอยากให้ได้ไปเนี่ยวิชานี้คือ ...</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>แล้วคุณเลือกสวิตช์ไหนบ้าง งาน ทีนี้อีกอันนึงที...</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>เตรียมมาเตรียมเป็นมาแล้วแต่ว่าเหลืออยู่บนเนินเ...</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  token_count\n",
       "0    จุดจุดจุด อ่ะก่อนอื่น คนเรือง เลือดสำคัญต่อก็ค...          964\n",
       "1    ก็ได้เสียงประมาณนั้นคล้ายคล้ายกับแคลคูลัสใช่ไห...          970\n",
       "2    แม้ว่าโจทย์เราจะทำโจทย์ทุกอันให้มีความจริงอยู่...          979\n",
       "3    ซิทีฟ เป็น office ไม่ใช่ media ฟังก์ชัน นะครับ...          949\n",
       "4    สมการนี้ เอ๊ะเราจะหายังไงดี ถ้ามองเป็นมุมมองขอ...          953\n",
       "..                                                 ...          ...\n",
       "325  บิลโอเค ก่อนโยกครั้นถัดไปครับ ไม่ได้นะครับในบา...          965\n",
       "326  ไปอัพเดทท็อปในการเลือก ไปอัพเดทในการเลือกอัพเด...          999\n",
       "327  นะครับแต่สิ่งที่ผมอยากให้ได้ไปเนี่ยวิชานี้คือ ...          930\n",
       "328  แล้วคุณเลือกสวิตช์ไหนบ้าง งาน ทีนี้อีกอันนึงที...          896\n",
       "329  เตรียมมาเตรียมเป็นมาแล้วแต่ว่าเหลืออยู่บนเนินเ...          515\n",
       "\n",
       "[330 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../all_data/concatenated_transcript_LDA_file.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "\n",
    "stopword = thai_stopwords()\n",
    "\n",
    "def preprocess(text):\n",
    "  token_ls = word_tokenize(text,keep_whitespace=False,engine='attacut')\n",
    "  result = []\n",
    "  for token in token_ls:\n",
    "    if len(token) > 3 and token not in stopword:\n",
    "      result.append(token)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_ls'] = df['text'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>token_ls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>จุดจุดจุด อ่ะก่อนอื่น คนเรือง เลือดสำคัญต่อก็ค...</td>\n",
       "      <td>964</td>\n",
       "      <td>[เรือง, เลือด, สัปดาห์, หน้า, เทอม, ออกภาพ, เด...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ก็ได้เสียงประมาณนั้นคล้ายคล้ายกับแคลคูลัสใช่ไห...</td>\n",
       "      <td>970</td>\n",
       "      <td>[เสียง, แคลคูลัส, เรียน, แอลกูลัสเยฉะนั้น, โจท...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>แม้ว่าโจทย์เราจะทำโจทย์ทุกอันให้มีความจริงอยู่...</td>\n",
       "      <td>979</td>\n",
       "      <td>[โจทย์, โจทย์, เอกซ์, ผลิต, ครึ่ง, ทีวี, ร้อย,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  token_count  \\\n",
       "0  จุดจุดจุด อ่ะก่อนอื่น คนเรือง เลือดสำคัญต่อก็ค...          964   \n",
       "1  ก็ได้เสียงประมาณนั้นคล้ายคล้ายกับแคลคูลัสใช่ไห...          970   \n",
       "2  แม้ว่าโจทย์เราจะทำโจทย์ทุกอันให้มีความจริงอยู่...          979   \n",
       "\n",
       "                                            token_ls  \n",
       "0  [เรือง, เลือด, สัปดาห์, หน้า, เทอม, ออกภาพ, เด...  \n",
       "1  [เสียง, แคลคูลัส, เรียน, แอลกูลัสเยฉะนั้น, โจท...  \n",
       "2  [โจทย์, โจทย์, เอกซ์, ผลิต, ครึ่ง, ทีวี, ร้อย,...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303306"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.token_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (330)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     phrase_list \u001b[38;5;241m=\u001b[39m [phrase\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m phrase \u001b[38;5;129;01min\u001b[39;00m transformed_sentence \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m phrase]\n\u001b[0;32m     30\u001b[0m     bigram_ls\u001b[38;5;241m.\u001b[39mappend(phrase_list)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigram\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m bigram_ls\n\u001b[0;32m     32\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_with_bigram\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(change_to_bigram,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\pandas\\core\\frame.py:3977\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3977\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\pandas\\core\\frame.py:4171\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4163\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4169\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4171\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4174\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4175\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4176\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4177\u001b[0m     ):\n\u001b[0;32m   4178\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\pandas\\core\\frame.py:4904\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4904\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (3) does not match length of index (330)"
     ]
    }
   ],
   "source": [
    "#  bigram for english\n",
    "# from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# # check english word\n",
    "# def is_eng(word):\n",
    "#   eng = 'abcdefghijklmnopqrstuvwxyz'\n",
    "#   word = word.lower()\n",
    "#   for e in word:\n",
    "#     if (e not in eng): return False\n",
    "#   return True\n",
    "\n",
    "# def change_to_bigram(row):\n",
    "#   return_ls = row['token'].copy()\n",
    "#   if (row['bigram'] == []): return return_ls\n",
    "#   for e in row['bigram']:\n",
    "#     token_ls = e.split()\n",
    "#     if (len(token_ls) > 2): return return_ls\n",
    "#     if (is_eng(token_ls[0]) and is_eng(token_ls[1])):\n",
    "#       idx = return_ls.index(token_ls[0])\n",
    "#       return_ls[idx] = e\n",
    "#       return_ls.pop(idx+1)\n",
    "#   return return_ls\n",
    "\n",
    "# bigram_ls = []\n",
    "# phrases = Phrases(df, min_count=1, threshold=100)\n",
    "# phraser = Phraser(phrases)\n",
    "# for sentence in df:\n",
    "#     transformed_sentence = phraser[sentence]\n",
    "#     phrase_list = [phrase.replace(\"_\", \" \") for phrase in transformed_sentence if \"_\" in phrase]\n",
    "#     bigram_ls.append(phrase_list)\n",
    "# df['bigram'] = bigram_ls\n",
    "# df['token_with_bigram'] = df.apply(change_to_bigram,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697\n",
      "2723\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df['token_ls'])\n",
    "print(len(dictionary))\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=None)\n",
    "print(len(dictionary))\n",
    "\n",
    "# bow_corpus is embedding vector of each sentence\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in df['token_ls']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dic for count word (do stop word)\n",
    "count_word = [[i,0] for i in range(len(dictionary))]\n",
    "\n",
    "for i in range(len(bow_corpus)):\n",
    "  for j in range(len(bow_corpus[i])):\n",
    "    word_idx,freq = bow_corpus[i][j]\n",
    "    count_word[word_idx][1] += freq\n",
    "\n",
    "sort_freq = sorted(count_word, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เอ็น 653 23.981\n",
      "โอเมก้า 433 15.902\n",
      "ก้อน 413 15.167\n",
      "เจ้าตัว 398 14.616\n",
      "โจทย์ 397 14.58\n",
      "สูตร 390 14.322\n",
      "เรียน 365 13.404\n",
      "หน้าตา 338 12.413\n",
      "เนาะ 319 11.715\n",
      "ไหร่ 304 11.164\n",
      "เอ่อ 261 9.585\n",
      "ข้อมูล 261 9.585\n",
      "วิธี 258 9.475\n",
      "เลือก 257 9.438\n",
      "รูปแบบ 237 8.704\n",
      "ตัวอย่าง 235 8.63\n",
      "สมมุติ 234 8.593\n",
      "สมการ 232 8.52\n",
      "อ่าน 230 8.447\n",
      "เก้า 217 7.969\n",
      "เปอร์เซ็นต์ 209 7.675\n",
      "เดลต้า 208 7.639\n",
      "จำนวน 204 7.492\n",
      "สุดท้าย 203 7.455\n",
      "บ้าน 194 7.124\n",
      "หมาย 185 6.794\n",
      "ร้อย 184 6.757\n",
      "เปล่า 180 6.61\n",
      "คำนวณ 179 6.574\n",
      "เล่น 175 6.427\n",
      "ระบบ 170 6.243\n",
      "โอกาส 165 6.059\n",
      "เอ็ม 158 5.802\n",
      "เรื่อยเรื่อย 153 5.619\n",
      "ฟังก์ชัน 152 5.582\n",
      "อียก 152 5.582\n",
      "เส้น 151 5.545\n",
      "integrate 143 5.252\n",
      "สัญญา 143 5.252\n",
      "สนใจ 136 4.994\n",
      "ซื้อ 136 4.994\n",
      "เพื่อน 134 4.921\n",
      "แปลง 134 4.921\n",
      "นะนะ 132 4.848\n",
      "ชื่อ 131 4.811\n",
      "convolution 129 4.737\n",
      "เหลี่ยม 128 4.701\n",
      "งั้น 126 4.627\n",
      "เจ็ด 126 4.627\n",
      "พิจารณา 121 4.444\n",
      "หลัก 117 4.297\n",
      "กลาย 117 4.297\n",
      "transform 112 4.113\n",
      "สำหรับ 111 4.076\n",
      "ซ้าย 111 4.076\n",
      "ปุ๊บ 110 4.04\n",
      "input 110 4.04\n",
      "ฟังก์ชั่น 110 4.04\n",
      "วิชา 109 4.003\n",
      "เหรียญ 109 4.003\n",
      "เฉลี่ย 107 3.929\n",
      "เนาะนะ 107 3.929\n",
      "ปกติ 106 3.893\n",
      "เช็ค 103 3.783\n",
      "ทดลอง 103 3.783\n",
      "ขนาด 102 3.746\n",
      "เสียง 102 3.746\n",
      "สังเกต 101 3.709\n",
      "อยู่แล้ว 99 3.636\n",
      "นาที 97 3.562\n",
      "ฟอร์ม 96 3.526\n",
      "หยิบ 96 3.526\n",
      "สรุป 94 3.452\n",
      "output 94 3.452\n",
      "จุดห้า 92 3.379\n",
      "furia 92 3.379\n",
      "ต้องการ 91 3.342\n",
      "เด็ก 91 3.342\n",
      "ล่าง 89 3.268\n",
      "สร้าง 89 3.268\n",
      "มุมมอง 88 3.232\n",
      "ปัญหา 88 3.232\n",
      "เฮ้ย 87 3.195\n",
      "เทียบ 87 3.195\n",
      "โชว์ 86 3.158\n",
      "ครึ่ง 85 3.122\n",
      "เกี่ยว 84 3.085\n",
      "ศุกร์ 82 3.011\n",
      "คะแนน 81 2.975\n",
      "สมมติ 81 2.975\n",
      "หลักหลัก 80 2.938\n",
      "power 80 2.938\n",
      "อินฟินิตี้ 79 2.901\n",
      "ออนไลน์ 77 2.828\n",
      "แน่นอน 75 2.754\n",
      "เลื่อน 75 2.754\n",
      "กลาง 73 2.681\n",
      "data 72 2.644\n",
      "เอ็ด 72 2.644\n",
      "อธิบาย 71 2.607\n",
      "เงิน 70 2.571\n",
      "สัมพันธ์ 69 2.534\n",
      "เมื่อกี้ 68 2.497\n",
      "เต็ม 67 2.461\n",
      "อย่า 67 2.461\n",
      "พื้นที่ 66 2.424\n",
      "นั่ง 65 2.387\n",
      "กราฟ 65 2.387\n",
      "ห้อง 64 2.35\n",
      "สไลด์ 63 2.314\n",
      "เอ็กซ์ที 63 2.314\n",
      "เดือน 62 2.277\n",
      "แบ่ง 61 2.24\n",
      "คอร์ส 61 2.24\n",
      "โปรแกรม 60 2.203\n",
      "แตกต่าง 60 2.203\n",
      "point 59 2.167\n",
      "อินทิเกรต 59 2.167\n",
      "วิ่ง 58 2.13\n",
      "กระจาย 58 2.13\n",
      "ลูกค้า 57 2.093\n",
      "ตำแหน่ง 57 2.093\n",
      "อาทิตย์ 57 2.093\n",
      "สมบัติ 56 2.057\n",
      "เอ็กซ์เอ็น 56 2.057\n",
      "ไฟล์ 55 2.02\n",
      "สองสาม 55 2.02\n",
      "เดี๋ยวเดี๋ยว 55 2.02\n",
      "recency 55 2.02\n",
      "กระบวนการ 54 1.983\n",
      "ลักษณะ 54 1.983\n",
      "ทิ้ง 54 1.983\n",
      "sample 54 1.983\n",
      "ความหมาย 53 1.946\n",
      "ซิกแนล 53 1.946\n",
      "ผลลัพธ์ 52 1.91\n",
      "solution 51 1.873\n",
      "เติม 51 1.873\n",
      "พรีเซนต์ 51 1.873\n",
      "ขยับ 50 1.836\n",
      "ชีวิต 50 1.836\n",
      "ปิ้ง 50 1.836\n",
      "ซิงค์ 50 1.836\n",
      "ทราย 49 1.799\n",
      "เชิง 48 1.763\n",
      "ครู่ 48 1.763\n",
      "เรียว 47 1.726\n",
      "ร้าน 47 1.726\n",
      "เมกา 47 1.726\n",
      "เสมอ 46 1.689\n",
      "เครื่อง 45 1.653\n",
      "เพลง 45 1.653\n",
      "ระวัง 45 1.653\n",
      "จันทร์ 45 1.653\n",
      "system 45 1.653\n",
      "ทรานฟอร์ม 45 1.653\n",
      "time 45 1.653\n",
      "ตาราง 44 1.616\n",
      "รู้จัก 44 1.616\n",
      "เก่า 43 1.579\n",
      "เล่ม 43 1.579\n",
      "แจ้ง 43 1.579\n",
      "สเกล 43 1.579\n",
      "user 43 1.579\n",
      "process 42 1.542\n",
      "extreme 42 1.542\n",
      "หัวข้อ 42 1.542\n",
      "มั้ง 42 1.542\n",
      "สัมประสิทธิ์ 42 1.542\n",
      "โดเมน 42 1.542\n",
      "repeat 42 1.542\n",
      "กระดาษ 41 1.506\n",
      "ต่างต่าง 41 1.506\n",
      "ฝั่ง 41 1.506\n",
      "อาร์ 41 1.506\n",
      "เงี้ย 41 1.506\n",
      "signal 39 1.432\n",
      "ประโยชน์ 39 1.432\n",
      "เริ่มต้น 39 1.432\n",
      "ย้าย 39 1.432\n",
      "independent 38 1.396\n",
      "ฟิลเตอร์ 38 1.396\n",
      "เจโอเมก้า 38 1.396\n",
      "เลี้ยง 38 1.396\n",
      "ฮาร์มอนิก 38 1.396\n",
      "น้อง 37 1.359\n",
      "หนังสือ 37 1.359\n",
      "แป๊บ 37 1.359\n",
      "คีย์ 37 1.359\n",
      "เดต้า 37 1.359\n",
      "distribution 37 1.359\n",
      "series 37 1.359\n",
      "สัปดาห์ 36 1.322\n",
      "facebook 36 1.322\n",
      "ชัดเจน 36 1.322\n",
      "ขยาย 36 1.322\n",
      "ไซน์ 36 1.322\n",
      "คุณสมบัติ 35 1.285\n",
      "เครื่องหมาย 35 1.285\n",
      "random 35 1.285\n",
      "value 35 1.285\n",
      "ค่อยค่อย 35 1.285\n",
      "ยูที 35 1.285\n",
      "เอเค 35 1.285\n",
      "ท้าย 34 1.249\n",
      "case 34 1.249\n",
      "เตรียม 34 1.249\n",
      "complex 34 1.249\n",
      "แมกนิจูด 34 1.249\n",
      "property 34 1.249\n",
      "เอลบ 34 1.249\n",
      "ไฟฟ้า 33 1.212\n",
      "คลิป 33 1.212\n",
      "แปลก 33 1.212\n",
      "สลับ 33 1.212\n",
      "คลิก 33 1.212\n",
      "ตัวตัว 33 1.212\n",
      "เนื้อหา 32 1.175\n",
      "ท่าน 32 1.175\n",
      "เนี้ย 32 1.175\n",
      "ได้ยิน 32 1.175\n",
      "แคร์ 32 1.175\n",
      "หน่วย 32 1.175\n",
      "อาเซียน 32 1.175\n",
      "คลื่น 32 1.175\n",
      "เอเอ็น 32 1.175\n",
      "เซต้า 32 1.175\n",
      "optimization 31 1.138\n",
      "เนื่อง 31 1.138\n",
      "basic 31 1.138\n",
      "เยอะเยอะ 31 1.138\n",
      "คราบ 31 1.138\n",
      "youtube 31 1.138\n",
      "แน่ใจ 30 1.102\n",
      "ทราบ 30 1.102\n",
      "เว็บไซต์ 30 1.102\n",
      "เจ้า 30 1.102\n",
      "วายเอ็น 30 1.102\n",
      "โมเดล 30 1.102\n",
      "คอนจูเกต 30 1.102\n",
      "อ้าว 29 1.065\n",
      "บริษัท 29 1.065\n",
      "continuous 29 1.065\n",
      "expo 29 1.065\n",
      "แนะนำ 28 1.028\n",
      "line 28 1.028\n",
      "standard 28 1.028\n",
      "พิสูจน์ 28 1.028\n",
      "เขียว 28 1.028\n",
      "แต้ม 28 1.028\n",
      "กระบวน 28 1.028\n",
      "แน่แน่ 28 1.028\n",
      "คุ้นเคย 28 1.028\n",
      "imaginary 28 1.028\n",
      "เอชเอ็น 28 1.028\n",
      "อินพุท 28 1.028\n",
      "ซีรีส์ 28 1.028\n",
      "เรียบร้อย 27 0.992\n",
      "หวัง 27 0.992\n",
      "ห่าง 27 0.992\n",
      "เฉลย 27 0.992\n",
      "รู้สึก 27 0.992\n",
      "application 27 0.992\n",
      "พล็อต 27 0.992\n",
      "ล็อค 27 0.992\n",
      "ยูเอ็น 27 0.992\n",
      "normal 27 0.992\n",
      "customer 27 0.992\n",
      "จินตนาการ 26 0.955\n",
      "วีดีโอ 26 0.955\n",
      "พิมพ์ 26 0.955\n",
      "หุ้น 26 0.955\n",
      "เป็นลบ 26 0.955\n",
      "หรอก 26 0.955\n",
      "ชั่วโมง 26 0.955\n",
      "วัคซีน 26 0.955\n",
      "ซ้ำกัน 26 0.955\n",
      "ฮาร์โมนิค 26 0.955\n",
      "อินตี้ 26 0.955\n",
      "ปั๊บ 26 0.955\n",
      "เจเค 26 0.955\n",
      "จิ้ม 25 0.918\n",
      "ประเภท 25 0.918\n",
      "form 25 0.918\n",
      "ไอเดีย 25 0.918\n",
      "เสริม 25 0.918\n",
      "เหนื่อย 25 0.918\n",
      "โฟกัส 25 0.918\n",
      "จ่าย 25 0.918\n",
      "ทาวน์ 25 0.918\n",
      "หยุด 24 0.881\n",
      "มิติ 24 0.881\n",
      "work 24 0.881\n",
      "ล้าน 24 0.881\n",
      "สเต็ป 24 0.881\n",
      "ศูนย์ศูนย์ 24 0.881\n",
      "เดิน 24 0.881\n",
      "ช่อง 24 0.881\n",
      "number 24 0.881\n",
      "มั่ว 24 0.881\n",
      "represent 24 0.881\n",
      "เอาท์ 24 0.881\n",
      "ดีไซน์ 24 0.881\n",
      "สุ่ม 24 0.881\n",
      "ง่ายง่าย 23 0.845\n",
      "ภาษา 23 0.845\n",
      "ราคา 23 0.845\n",
      "รายละเอียด 23 0.845\n",
      "เวิร์ค 23 0.845\n",
      "เซ็น 23 0.845\n",
      "event 23 0.845\n",
      "คงที่ 23 0.845\n",
      "กล้า 23 0.845\n",
      "ลิมิต 23 0.845\n",
      "เอ่ย 22 0.808\n",
      "ปลาย 22 0.808\n",
      "ลองลอง 22 0.808\n",
      "ห้าม 22 0.808\n",
      "อาร์ม 22 0.808\n",
      "ปล่อย 22 0.808\n",
      "เล่า 22 0.808\n",
      "พิเศษ 22 0.808\n",
      "เล็กเล็ก 22 0.808\n",
      "เบต้า 22 0.808\n",
      "สงสัย 22 0.808\n",
      "discrete 22 0.808\n",
      "component 22 0.808\n",
      "พาวเวอร์ 22 0.808\n",
      "คอนทินิว 22 0.808\n",
      "อิมเพ้า 22 0.808\n",
      "คุกกี้ 22 0.808\n",
      "หมื่น 21 0.771\n",
      "เทอม 21 0.771\n",
      "ดีดี 21 0.771\n",
      "ตรงไปตรงมา 21 0.771\n",
      "ตัดสินใจ 21 0.771\n",
      "ธรรมดา 21 0.771\n",
      "เย็น 21 0.771\n",
      "หลุด 21 0.771\n",
      "step 21 0.771\n",
      "สำเร็จ 21 0.771\n",
      "free 21 0.771\n",
      "มั่นใจ 21 0.771\n",
      "fundamental 21 0.771\n",
      "คะลบ 21 0.771\n",
      "ศึกษา 21 0.771\n",
      "ซิกนัม 21 0.771\n",
      "ทั่วไป 20 0.734\n",
      "ประกาศ 20 0.734\n",
      "คอมพิวเตอร์ 20 0.734\n",
      "จำกัด 20 0.734\n",
      "สัดส่วน 20 0.734\n",
      "content 20 0.734\n",
      "ตีความ 20 0.734\n",
      "program 20 0.734\n",
      "เอ๊ะ 20 0.734\n",
      "ลบห้า 20 0.734\n",
      "concept 20 0.734\n",
      "exponential 20 0.734\n",
      "ประเทศ 20 0.734\n",
      "ชั้น 20 0.734\n",
      "สนุก 20 0.734\n",
      "วิเคราะห์ 20 0.734\n",
      "อินเตอร์ 20 0.734\n",
      "ทีลบ 20 0.734\n",
      "คอนโด 20 0.734\n",
      "domain 20 0.734\n",
      "คร่าวคร่าว 20 0.734\n",
      "นายก 20 0.734\n",
      "สลาย 19 0.698\n",
      "ธุรกิจ 19 0.698\n",
      "แทรก 19 0.698\n",
      "effect 19 0.698\n",
      "แบรนด์ 19 0.698\n",
      "บรรทัด 19 0.698\n",
      "อาการ 19 0.698\n",
      "นิยาม 19 0.698\n",
      "แชร์ 19 0.698\n",
      "การันตี 19 0.698\n",
      "สองสามสี่ห้า 19 0.698\n",
      "check 19 0.698\n",
      "เงื่อนไข 19 0.698\n",
      "ปริมาณ 19 0.698\n",
      "alpha 19 0.698\n",
      "เมก้า 19 0.698\n",
      "พลอต 19 0.698\n",
      "product 19 0.698\n",
      "valence 19 0.698\n",
      "reward 19 0.698\n",
      "setting 18 0.661\n",
      "ชัวร์ 18 0.661\n",
      "อัตรา 18 0.661\n",
      "ตรวจ 18 0.661\n",
      "มาตรฐาน 18 0.661\n",
      "define 18 0.661\n",
      "ข้าม 18 0.661\n",
      "ระดับ 18 0.661\n",
      "เหรอ 18 0.661\n",
      "โหลด 18 0.661\n",
      "หมุน 18 0.661\n",
      "ไลน์ 18 0.661\n",
      "กลัว 18 0.661\n",
      "ลิสต์ 18 0.661\n",
      "ไลฟ์ 18 0.661\n",
      "ต่อเนื่อง 18 0.661\n",
      "พลิก 18 0.661\n",
      "present 18 0.661\n",
      "พัดลม 18 0.661\n",
      "เปรียบเทียบ 18 0.661\n",
      "ลบเค 18 0.661\n",
      "น้ำเงิน 18 0.661\n",
      "ยูนิฟอร์ม 18 0.661\n",
      "บริเวณ 17 0.624\n",
      "เบสิค 17 0.624\n",
      "เจ๊ง 17 0.624\n",
      "เลิก 17 0.624\n",
      "สัญลักษณ์ 17 0.624\n",
      "ติดต่อ 17 0.624\n",
      "default 17 0.624\n",
      "หญิง 17 0.624\n",
      "พลังงาน 17 0.624\n",
      "วงจร 17 0.624\n",
      "มั่ง 17 0.624\n",
      "จูเกต 17 0.624\n",
      "invert 16 0.588\n",
      "ยี่สิบ 16 0.588\n",
      "หนัง 16 0.588\n",
      "ตั้งต้น 16 0.588\n",
      "สั่ง 16 0.588\n",
      "apple 16 0.588\n",
      "พาร์ท 16 0.588\n",
      "google 16 0.588\n",
      "นิ่ง 16 0.588\n",
      "เต้า 16 0.588\n",
      "เว็บ 16 0.588\n",
      "อะนะ 16 0.588\n",
      "ไทม์โดเมน 16 0.588\n",
      "plot 16 0.588\n",
      "เอสเอ็ม 16 0.588\n",
      "รางวัล 16 0.588\n",
      "เวอร์ชั่น 16 0.588\n",
      "function 15 0.551\n",
      "media 15 0.551\n",
      "เซ็ต 15 0.551\n",
      "เหนือ 15 0.551\n",
      "เอเอ็กซ์ 15 0.551\n",
      "infinity 15 0.551\n",
      "ว่าง 15 0.551\n",
      "ข่าว 15 0.551\n",
      "อนาคต 15 0.551\n",
      "บังคับ 15 0.551\n",
      "ละเอียด 15 0.551\n",
      "แผ่น 15 0.551\n",
      "control 15 0.551\n",
      "เซียน 15 0.551\n",
      "โน้ต 15 0.551\n",
      "แอมพลิจูด 15 0.551\n",
      "เอสเอ็น 15 0.551\n",
      "ย้อนกลับ 15 0.551\n",
      "พจน์ 15 0.551\n",
      "ดีโอเมก้า 15 0.551\n",
      "จุดสี่ 15 0.551\n",
      "poverty 15 0.551\n",
      "final 14 0.514\n",
      "โปรเจค 14 0.514\n",
      "tata 14 0.514\n",
      "ยกเว้น 14 0.514\n",
      "ชาติ 14 0.514\n",
      "คูณกัน 14 0.514\n",
      "ประโยค 14 0.514\n",
      "ชิ้น 14 0.514\n",
      "อาหาร 14 0.514\n",
      "เสิร์ช 14 0.514\n",
      "เซ็ท 14 0.514\n",
      "ห่วย 14 0.514\n",
      "อันนึง 14 0.514\n",
      "เช้า 14 0.514\n",
      "ปุ่ม 14 0.514\n",
      "เฉยเฉย 14 0.514\n",
      "excel 14 0.514\n",
      "โค้ช 14 0.514\n",
      "โบนัส 14 0.514\n",
      "มหาลัย 14 0.514\n",
      "อ้างอิง 14 0.514\n",
      "ซ้อน 14 0.514\n",
      "ตั้งใจ 14 0.514\n",
      "โครง 14 0.514\n",
      "ไทม์ 14 0.514\n",
      "frequency 14 0.514\n",
      "สเก็ต 14 0.514\n",
      "energy 14 0.514\n",
      "ดีที 14 0.514\n",
      "คาบนะ 14 0.514\n",
      "dependent 14 0.514\n",
      "split 14 0.514\n",
      "สไตล์ 13 0.477\n",
      "เป้าหมาย 13 0.477\n",
      "แต่ง 13 0.477\n",
      "ตลาด 13 0.477\n",
      "ถ้าถ้า 13 0.477\n",
      "ล็อก 13 0.477\n",
      "open 13 0.477\n",
      "เค้า 13 0.477\n",
      "หลอก 13 0.477\n",
      "สวัสดี 13 0.477\n",
      "เบื้อง 13 0.477\n",
      "อเมริกา 13 0.477\n",
      "เซ็นต์ 13 0.477\n",
      "คอมเพล็กซ์ 13 0.477\n",
      "filter 13 0.477\n",
      "ตรงกัน 13 0.477\n",
      "ซีเควนส์ 13 0.477\n",
      "เป็นฟังก์ชัน 13 0.477\n",
      "แอลฟา 13 0.477\n",
      "อัพเดท 12 0.441\n",
      "ผลิต 12 0.441\n",
      "สาขา 12 0.441\n",
      "โค้ด 12 0.441\n",
      "simple 12 0.441\n",
      "ติ๊ก 12 0.441\n",
      "report 12 0.441\n",
      "เม็ด 12 0.441\n",
      "ต่อเมื่อ 12 0.441\n",
      "เบอร์ 12 0.441\n",
      "ไวน์ 12 0.441\n",
      "อนุญาต 12 0.441\n",
      "อัลกอริทึม 12 0.441\n",
      "เอ็นเอ็น 12 0.441\n",
      "ศูนย์มัน 12 0.441\n",
      "ค่าย 12 0.441\n",
      "ร้อน 12 0.441\n",
      "ไอ้ตัว 12 0.441\n",
      "ไบนารี่ 12 0.441\n",
      "อัลฟ่า 12 0.441\n",
      "cover 12 0.441\n",
      "น้ำหนัก 12 0.441\n",
      "ประจำ 12 0.441\n",
      "พื้นฐาน 12 0.441\n",
      "แล็บ 12 0.441\n",
      "ไวไว 12 0.441\n",
      "คะคูณ 12 0.441\n",
      "เหตุการณ์ 12 0.441\n",
      "interval 12 0.441\n",
      "เอบี 12 0.441\n",
      "foie 12 0.441\n",
      "ส่วนเอ็น 12 0.441\n",
      "ถ่วง 12 0.441\n",
      "เมล์ 12 0.441\n",
      "zoom 12 0.441\n",
      "force 11 0.404\n",
      "สมุด 11 0.404\n",
      "learning 11 0.404\n",
      "โผล่ 11 0.404\n",
      "matic 11 0.404\n",
      "ฟาร์ม 11 0.404\n",
      "คณิตศาสตร์ 11 0.404\n",
      "ชั่น 11 0.404\n",
      "optimal 11 0.404\n",
      "ว่าว่า 11 0.404\n",
      "ค่าค่า 11 0.404\n",
      "นิดนึง 11 0.404\n",
      "แพลตฟอร์ม 11 0.404\n",
      "เทคนิค 11 0.404\n",
      "original 11 0.404\n",
      "หนัก 11 0.404\n",
      "brown 11 0.404\n",
      "ทฤษฎี 11 0.404\n",
      "ซิตี้ 11 0.404\n",
      "อะที 11 0.404\n",
      "รุ่น 11 0.404\n",
      "ช้อยส์ 11 0.404\n",
      "ขอบคุณ 11 0.404\n",
      "ระเบิด 11 0.404\n",
      "เซลล์ 11 0.404\n",
      "เมีย 11 0.404\n",
      "สาระ 11 0.404\n",
      "เครดิต 11 0.404\n",
      "จุฬา 11 0.404\n",
      "ผสมผสาน 11 0.404\n",
      "ขอโทษ 11 0.404\n",
      "pont 11 0.404\n",
      "freeny 11 0.404\n",
      "บ่าย 11 0.404\n",
      "average 11 0.404\n",
      "เอฟเอ็น 11 0.404\n",
      "เอสที 11 0.404\n",
      "ฟินิตี้ 11 0.404\n",
      "บวกลบ 11 0.404\n",
      "เอ็นลบ 11 0.404\n",
      "น้อยน้อย 11 0.404\n",
      "เอ็นโอเมก้า 11 0.404\n",
      "conversion 11 0.404\n",
      "มือถือ 11 0.404\n",
      "ทดสอบ 11 0.404\n",
      "varible 10 0.367\n",
      "ทีวี 10 0.367\n",
      "picture 10 0.367\n",
      "static 10 0.367\n",
      "ปุ๋ย 10 0.367\n",
      "หน้าที่ 10 0.367\n",
      "import 10 0.367\n",
      "real 10 0.367\n",
      "save 10 0.367\n",
      "division 10 0.367\n",
      "เรเดียน 10 0.367\n",
      "สวยงาม 10 0.367\n",
      "แปลกแปลก 10 0.367\n",
      "โง่โง่ 10 0.367\n",
      "หลากหลาย 10 0.367\n",
      "เกณฑ์ 10 0.367\n",
      "อ้อม 10 0.367\n",
      "intergate 10 0.367\n",
      "ย้อน 10 0.367\n",
      "จุดเจ็ด 10 0.367\n",
      "สมูท 10 0.367\n",
      "ไอดี 10 0.367\n",
      "คอมเม้นต์ 10 0.367\n",
      "ร้าย 10 0.367\n",
      "continue 10 0.367\n",
      "ประชากร 10 0.367\n",
      "แล็ป 10 0.367\n",
      "อินคา 10 0.367\n",
      "ว่าที่ 10 0.367\n",
      "เพลย์ 10 0.367\n",
      "คอนนิวส์ 10 0.367\n",
      "เนอะ 10 0.367\n",
      "กล้อง 10 0.367\n",
      "มากน้อย 10 0.367\n",
      "เอาเป็น 10 0.367\n",
      "ประจุ 10 0.367\n",
      "อีเว้นท์ 10 0.367\n",
      "อีเว่น 10 0.367\n",
      "อพเพอร์ตี้ 10 0.367\n",
      "ยูนิตสเต็ป 10 0.367\n",
      "สเกลลิ่ง 10 0.367\n",
      "ออฟไลน์ 10 0.367\n",
      "เป็นไง 10 0.367\n",
      "เคลบ 10 0.367\n",
      "ช่าง 10 0.367\n",
      "เจ้าตัวโอเมก้า 10 0.367\n",
      "converse 10 0.367\n",
      "อายุ 10 0.367\n",
      "โปรโมชั่น 10 0.367\n",
      "part 9 0.331\n",
      "เก่ง 9 0.331\n",
      "decision 9 0.331\n",
      "optimize 9 0.331\n",
      "ป่วย 9 0.331\n",
      "ส่วนห้า 9 0.331\n",
      "เสี่ยง 9 0.331\n",
      "แฮมทา 9 0.331\n",
      "ครับผม 9 0.331\n",
      "internet 9 0.331\n",
      "เล็บ 9 0.331\n",
      "ม่วง 9 0.331\n",
      "หัวใจ 9 0.331\n",
      "ติดตาม 9 0.331\n",
      "บริโภค 9 0.331\n",
      "ถ่าย 9 0.331\n",
      "เอชเค 9 0.331\n",
      "พ้อยท์ 9 0.331\n",
      "เรือ 9 0.331\n",
      "ดาวน์ 9 0.331\n",
      "rate 9 0.331\n",
      "กังวล 9 0.331\n",
      "ข้าว 9 0.331\n",
      "general 9 0.331\n",
      "size 9 0.331\n",
      "กล่อง 9 0.331\n",
      "ฟีเจอร์ 9 0.331\n",
      "ดิสคอร์ด 9 0.331\n",
      "คะจริง 9 0.331\n",
      "กำลังใจ 9 0.331\n",
      "ครีม 9 0.331\n",
      "กระแส 9 0.331\n",
      "อ้วน 9 0.331\n",
      "ตรงข้าม 9 0.331\n",
      "สเปคตรัม 9 0.331\n",
      "เอนเนอร์ 9 0.331\n",
      "มาคูณ 9 0.331\n",
      "ซัมติ้ง 9 0.331\n",
      "อิมเพ้าเทรน 9 0.331\n",
      "คอนโวล 9 0.331\n",
      "respon 9 0.331\n",
      "moving 9 0.331\n",
      "high 9 0.331\n",
      "สมมาตร 9 0.331\n",
      "งงงง 9 0.331\n",
      "ครอบคลุม 9 0.331\n",
      "ชมพู 9 0.331\n",
      "บีส่วน 9 0.331\n",
      "เจ็บ 9 0.331\n",
      "เท้า 9 0.331\n",
      "คูณลบ 9 0.331\n",
      "เอ็กซ์เอ็ม 9 0.331\n",
      "เอ็นศูนย์ 9 0.331\n",
      "เอ็นคูณ 9 0.331\n",
      "คอลเลชั่น 9 0.331\n",
      "นะโอเค 9 0.331\n",
      "even 9 0.331\n",
      "central 9 0.331\n",
      "เอ็กซ์บาร์ 9 0.331\n",
      "estimate 9 0.331\n",
      "explore 9 0.331\n",
      "formula 8 0.294\n",
      "อันดับ 8 0.294\n",
      "active 8 0.294\n",
      "feature 8 0.294\n",
      "resource 8 0.294\n",
      "index 8 0.294\n",
      "ละคร 8 0.294\n",
      "constrain 8 0.294\n",
      "contain 8 0.294\n",
      "polity 8 0.294\n",
      "บ้าบอ 8 0.294\n",
      "เช็คเช็ค 8 0.294\n",
      "unit 8 0.294\n",
      "ตรงตรง 8 0.294\n",
      "โต๊ะ 8 0.294\n",
      "video 8 0.294\n",
      "เตอร์ 8 0.294\n",
      "เอ้ย 8 0.294\n",
      "พอยท์ 8 0.294\n",
      "จุดสอง 8 0.294\n",
      "เผอิญ 8 0.294\n",
      "หัวข้อใหม่ 8 0.294\n",
      "library 8 0.294\n",
      "operation 8 0.294\n",
      "เกมส์ 8 0.294\n",
      "หลักการ 8 0.294\n",
      "บริการ 8 0.294\n",
      "วกบี 8 0.294\n",
      "น้ำมัน 8 0.294\n",
      "คอนเฟิร์ม 8 0.294\n",
      "lecture 8 0.294\n",
      "คอนโทรล 8 0.294\n",
      "คอนทินิวอัส 8 0.294\n",
      "นิดเดียว 8 0.294\n",
      "อากาศ 8 0.294\n",
      "ดิสคลีน 8 0.294\n",
      "เชื่อม 8 0.294\n",
      "poperty 8 0.294\n",
      "fundametal 8 0.294\n",
      "คุ้นคุ้น 8 0.294\n",
      "จำสูตร 8 0.294\n",
      "reflex 8 0.294\n",
      "นะคะ 8 0.294\n",
      "เว้น 8 0.294\n",
      "อุ้ย 8 0.294\n",
      "lowpass 8 0.294\n",
      "integer 8 0.294\n",
      "อินเทรน 8 0.294\n",
      "sampling 8 0.294\n",
      "ซีเรียส 8 0.294\n",
      "ลิ้งก์ 8 0.294\n",
      "face 8 0.294\n",
      "เดลต้าเอ็น 8 0.294\n",
      "font 8 0.294\n",
      "ดีเอส 8 0.294\n",
      "พีที 8 0.294\n",
      "เอที 8 0.294\n",
      "ใหญ่ใหญ่ 8 0.294\n",
      "เอาท์พุท 8 0.294\n",
      "อาวุธ 8 0.294\n",
      "invariance 8 0.294\n",
      "design 8 0.294\n",
      "siri 8 0.294\n",
      "จุดสาม 8 0.294\n",
      "presentation 8 0.294\n",
      "fora 8 0.294\n",
      "ลอตเตอรี่ 8 0.294\n",
      "จักร 8 0.294\n",
      "ซีเรีย 8 0.294\n",
      "เอ็มบีอี 8 0.294\n",
      "bandit 8 0.294\n",
      "บาบาบา 7 0.257\n",
      "เรียนรู้ 7 0.257\n",
      "สตอรี่ 7 0.257\n",
      "ไอที 7 0.257\n",
      "ร่าง 7 0.257\n",
      "เอ็กซ์เอ็กซ์ 7 0.257\n",
      "กำไร 7 0.257\n",
      "ฉลาด 7 0.257\n",
      "ทั้งทั้ง 7 0.257\n",
      "เหลือง 7 0.257\n",
      "โอเคที 7 0.257\n",
      "แอลพี 7 0.257\n",
      "ประเด็น 7 0.257\n",
      "definition 7 0.257\n",
      "matrix 7 0.257\n",
      "ชัดชัด 7 0.257\n",
      "อ่าว 7 0.257\n",
      "เอ็นเค 7 0.257\n",
      "โซลูชั่น 7 0.257\n",
      "commination 7 0.257\n",
      "ริจินอล 7 0.257\n",
      "เสมือน 7 0.257\n",
      "ทะลุ 7 0.257\n",
      "แบงค์ 7 0.257\n",
      "พลอย 7 0.257\n",
      "เดี๋ยวเดี๋ยวเดี๋ยว 7 0.257\n",
      "live 7 0.257\n",
      "ยุ่ง 7 0.257\n",
      "รายการ 7 0.257\n",
      "ตราบ 7 0.257\n",
      "word 7 0.257\n",
      "เป่า 7 0.257\n",
      "โอ๊ย 7 0.257\n",
      "อ้าง 7 0.257\n",
      "พริก 7 0.257\n",
      "ใกล้เคียง 7 0.257\n",
      "พันธุ์ 7 0.257\n",
      "แอลที 7 0.257\n",
      "โทรศัพท์ 7 0.257\n",
      "อัลฟา 7 0.257\n",
      "เอ้า 7 0.257\n",
      "เที่ยว 7 0.257\n",
      "เซ็ทอัพ 7 0.257\n",
      "true 7 0.257\n",
      "เดี๋ยวก่อน 7 0.257\n",
      "เลคเชอร์ 7 0.257\n",
      "เอกชน 7 0.257\n",
      "ไพทอน 7 0.257\n",
      "เร็วเร็ว 7 0.257\n",
      "ชมลิ้ง 7 0.257\n",
      "วินาที 7 0.257\n",
      "พีเรียด 7 0.257\n",
      "โพสต์ 7 0.257\n",
      "พลาด 7 0.257\n",
      "คะเอ็กซ์ 7 0.257\n",
      "ศูนย์ก้อน 7 0.257\n",
      "ship 7 0.257\n",
      "code 7 0.257\n",
      "ดีกรี 7 0.257\n",
      "กลับคืน 7 0.257\n",
      "ปั๊ม 7 0.257\n",
      "ลิ้ง 7 0.257\n",
      "แคมปิ้ง 7 0.257\n",
      "ปรากฏการณ์ 7 0.257\n",
      "กรอง 7 0.257\n",
      "คะออนไลน์ 7 0.257\n",
      "พรีเวน 7 0.257\n",
      "ร้อง 7 0.257\n",
      "sequence 7 0.257\n",
      "error 7 0.257\n",
      "ซี่โดเมน 7 0.257\n",
      "edition 7 0.257\n",
      "หนี้ 7 0.257\n",
      "อ๊อด 7 0.257\n",
      "delta 7 0.257\n",
      "sitting 7 0.257\n",
      "ยูนิต 7 0.257\n",
      "ดิสครีท 7 0.257\n",
      "โลเตชั่น 7 0.257\n",
      "เอ็นยูเอ็น 7 0.257\n",
      "สูตรสูตร 7 0.257\n",
      "ทาว์ 7 0.257\n",
      "สองเอ 7 0.257\n",
      "representation 7 0.257\n",
      "คอมพ์ 7 0.257\n",
      "efficient 7 0.257\n",
      "มูลฐาน 7 0.257\n",
      "เป็นพาย 7 0.257\n",
      "เดี๋ยวนี้ 7 0.257\n",
      "ซับซ้อน 7 0.257\n",
      "เดลต้าโอเมก้า 7 0.257\n",
      "action 7 0.257\n",
      "expansion 7 0.257\n",
      "โฆษณา 7 0.257\n",
      "ศาสตร์ 7 0.257\n",
      "poppity 7 0.257\n",
      "เกาเซียน 7 0.257\n",
      "คาสิโน 7 0.257\n",
      "จุดหก 7 0.257\n",
      "ฟันธง 7 0.257\n",
      "intel 7 0.257\n",
      "testing 7 0.257\n",
      "reject 7 0.257\n",
      "session 7 0.257\n",
      "softmat 7 0.257\n",
      "core 6 0.22\n",
      "maximize 6 0.22\n",
      "lanna 6 0.22\n",
      "กระจอก 6 0.22\n",
      "เอกซ์ 6 0.22\n",
      "แต่งงาน 6 0.22\n",
      "โอเคมี 6 0.22\n",
      "life 6 0.22\n",
      "nation 6 0.22\n",
      "เป๊ะ 6 0.22\n",
      "unity 6 0.22\n",
      "ฝึกหัด 6 0.22\n",
      "click 6 0.22\n",
      "negative 6 0.22\n",
      "สี่ห้า 6 0.22\n",
      "กรอบ 6 0.22\n",
      "bound 6 0.22\n",
      "peiple 6 0.22\n",
      "space 6 0.22\n",
      "น่ารัก 6 0.22\n",
      "simplex 6 0.22\n",
      "ควาย 6 0.22\n",
      "สีสี 6 0.22\n",
      "constant 6 0.22\n",
      "เรียง 6 0.22\n",
      "สมอง 6 0.22\n",
      "เมตร 6 0.22\n",
      "เวที 6 0.22\n",
      "ลีเดีย 6 0.22\n",
      "รีวิว 6 0.22\n",
      "เกียจ 6 0.22\n",
      "สอบถาม 6 0.22\n",
      "เอ็นเอ 6 0.22\n",
      "device 6 0.22\n",
      "over 6 0.22\n",
      "pity 6 0.22\n",
      "พอใจ 6 0.22\n",
      "limit 6 0.22\n",
      "อาร์ที 6 0.22\n",
      "แรนดอม 6 0.22\n",
      "version 6 0.22\n",
      "quiz 6 0.22\n",
      "ตกลง 6 0.22\n",
      "เรียล 6 0.22\n",
      "ยืดหยุ่น 6 0.22\n",
      "รักษา 6 0.22\n",
      "เอกพล 6 0.22\n",
      "พฤหัส 6 0.22\n",
      "เลนส์ 6 0.22\n",
      "ดิจิตอล 6 0.22\n",
      "คอนนิว 6 0.22\n",
      "ซิกเนล 6 0.22\n",
      "vayu 6 0.22\n",
      "อ่อน 6 0.22\n",
      "เตี้ย 6 0.22\n",
      "แล้วแต่ว่า 6 0.22\n",
      "เอ็ก 6 0.22\n",
      "เฟสมัน 6 0.22\n",
      "เจเคโอเมก้า 6 0.22\n",
      "อินเตอร์เตอร์ 6 0.22\n",
      "เคที 6 0.22\n",
      "สามคูณ 6 0.22\n",
      "visual 6 0.22\n",
      "expand 6 0.22\n",
      "total 6 0.22\n",
      "ลบที 6 0.22\n",
      "ดิคริ 6 0.22\n",
      "ซิ่ง 6 0.22\n",
      "ติ้ง 6 0.22\n",
      "พาสฟิลเตอร์ 6 0.22\n",
      "อ่ะนะ 6 0.22\n",
      "เนเจอร์ 6 0.22\n",
      "เดโม่ 6 0.22\n",
      "แนวโน้ม 6 0.22\n",
      "audio 6 0.22\n",
      "เทคโนโลยี 6 0.22\n",
      "โดเมนนะ 6 0.22\n",
      "คุ้น 6 0.22\n",
      "เอชที 6 0.22\n",
      "stable 6 0.22\n",
      "ลบอียก 6 0.22\n",
      "ค้าง 6 0.22\n",
      "ลงตัว 6 0.22\n",
      "ลบลบ 6 0.22\n",
      "เอ็กซอน 6 0.22\n",
      "ถึงเอ็น 6 0.22\n",
      "สินค้า 6 0.22\n",
      "เอ็กซ์เค 6 0.22\n",
      "อินเวิร์ต 6 0.22\n",
      "assume 6 0.22\n",
      "สล็อต 6 0.22\n",
      "พร็อพเพอร์ตี้ 6 0.22\n",
      "คอนโวลูชัน 6 0.22\n",
      "ทบทวน 6 0.22\n",
      "เอนะ 6 0.22\n",
      "ไฮไลท์ 6 0.22\n",
      "diet 6 0.22\n",
      "fraser 6 0.22\n",
      "โอเมก้าศูนย์ 6 0.22\n",
      "ฉบับ 6 0.22\n",
      "นัมเบอร์ 6 0.22\n",
      "เจยก 6 0.22\n",
      "secular 6 0.22\n",
      "basin 6 0.22\n",
      "ปริศนา 6 0.22\n",
      "very 6 0.22\n",
      "พีดีเอฟ 6 0.22\n",
      "แปรหนึ่ง 6 0.22\n",
      "exponent 6 0.22\n",
      "นอร์มอล 6 0.22\n",
      "คลาส 6 0.22\n",
      "copy 6 0.22\n",
      "ซิกม่า 6 0.22\n",
      "จุดแปด 6 0.22\n",
      "เอเซียน 6 0.22\n",
      "given 6 0.22\n",
      "รุ่ง 6 0.22\n",
      "confident 6 0.22\n",
      "สาเหตุ 6 0.22\n",
      "side 6 0.22\n",
      "เอชเอ 6 0.22\n",
      "คู่แข่ง 6 0.22\n",
      "เสื้อ 6 0.22\n",
      "slot 6 0.22\n",
      "exprit 6 0.22\n",
      "project 5 0.184\n",
      "การบ้าน 5 0.184\n",
      "สภาพ 5 0.184\n",
      "เทียน 5 0.184\n",
      "model 5 0.184\n",
      "แปรหลัก 5 0.184\n",
      "positive 5 0.184\n",
      "single 5 0.184\n",
      "การ์ตูน 5 0.184\n",
      "maximum 5 0.184\n",
      "metric 5 0.184\n",
      "image 5 0.184\n",
      "connect 5 0.184\n",
      "หนุ่ม 5 0.184\n",
      "เกลือ 5 0.184\n",
      "เส้นเส้น 5 0.184\n",
      "ระนาบ 5 0.184\n",
      "เบรค 5 0.184\n",
      "เป๊ะเป๊ะ 5 0.184\n",
      "equation 5 0.184\n",
      "stand 5 0.184\n",
      "soap 5 0.184\n",
      "solver 5 0.184\n",
      "แต่แต่ 5 0.184\n",
      "บวกเป็น 5 0.184\n",
      "ปลอม 5 0.184\n",
      "ศูนย์ปุ๊บ 5 0.184\n",
      "search 5 0.184\n",
      "คอมบิเนชั่น 5 0.184\n",
      "สับสน 5 0.184\n",
      "เดียน 5 0.184\n",
      "เปรียบ 5 0.184\n",
      "ยิ้ม 5 0.184\n",
      "เจ๋ง 5 0.184\n",
      "เอ็กซี่ 5 0.184\n",
      "ค่อยค่อยค่อยค่อย 5 0.184\n",
      "ติดลบ 5 0.184\n",
      "สองสามสี่ 5 0.184\n",
      "ข้อข้อ 5 0.184\n",
      "จารย์ 5 0.184\n",
      "ก๊อป 5 0.184\n",
      "มีเดีย 5 0.184\n",
      "agent 5 0.184\n",
      "ดูดู 5 0.184\n",
      "ฟิสิกส์ 5 0.184\n",
      "ไอ้ค่า 5 0.184\n",
      "ศูนย์ลบ 5 0.184\n",
      "ศูนย์เจ็ด 5 0.184\n",
      "generate 5 0.184\n",
      "ศูนย์ศูนย์ศูนย์ 5 0.184\n",
      "ment 5 0.184\n",
      "sigma 5 0.184\n",
      "happy 5 0.184\n",
      "อินเดีย 5 0.184\n",
      "เอียง 5 0.184\n",
      "เป็นฟังก์ชั่น 5 0.184\n",
      "round 5 0.184\n",
      "อุบาทว์ 5 0.184\n",
      "option 5 0.184\n",
      "ว้าว 5 0.184\n",
      "เชิญ 5 0.184\n",
      "วิวัฒนาการ 5 0.184\n",
      "เวอร์ 5 0.184\n",
      "เหมาะสม 5 0.184\n",
      "แข่ง 5 0.184\n",
      "นโยบาย 5 0.184\n",
      "discord 5 0.184\n",
      "ย้อนหลัง 5 0.184\n",
      "เบื่อ 5 0.184\n",
      "พาร์ทแรก 5 0.184\n",
      "เตรียมตัว 5 0.184\n",
      "analize 5 0.184\n",
      "processing 5 0.184\n",
      "เดินทาง 5 0.184\n",
      "ดนตรี 5 0.184\n",
      "ดีฟคลีน 5 0.184\n",
      "มิเตอร์ 5 0.184\n",
      "เฮิร์ต 5 0.184\n",
      "วงเล็บ 5 0.184\n",
      "โค้ง 5 0.184\n",
      "ซ่อน 5 0.184\n",
      "ต้าร์ 5 0.184\n",
      "ถี่โอเมก้า 5 0.184\n",
      "ฮาโมนิค 5 0.184\n",
      "หมดเลย 5 0.184\n",
      "ห่วง 5 0.184\n",
      "คะเอ 5 0.184\n",
      "สองที 5 0.184\n",
      "เลเวล 5 0.184\n",
      "พารามิเตอร์ 5 0.184\n",
      "แอปโซลูท 5 0.184\n",
      "โอ้โห 5 0.184\n",
      "ไซส์ 5 0.184\n",
      "hello 5 0.184\n",
      "โกรธ 5 0.184\n",
      "ดิฟครีท 5 0.184\n",
      "samping 5 0.184\n",
      "พี่ที 5 0.184\n",
      "โอเมก้าคูณ 5 0.184\n",
      "คอร์ 5 0.184\n",
      "ซีซี 5 0.184\n",
      "เป็นเป็นเป็น 5 0.184\n",
      "แดงแดง 5 0.184\n",
      "แม็กนิจูด 5 0.184\n",
      "ตกใจ 5 0.184\n",
      "ซีโดเมน 5 0.184\n",
      "ปั่น 5 0.184\n",
      "อัตโนมัติ 5 0.184\n",
      "page 5 0.184\n",
      "wave 5 0.184\n",
      "freedom 5 0.184\n",
      "ศัพท์ 5 0.184\n",
      "เจ้าตัววาย 5 0.184\n",
      "เอ็มลบ 5 0.184\n",
      "computational 5 0.184\n",
      "interpolation 5 0.184\n",
      "ไหมออนไลน์ 5 0.184\n",
      "ปากกา 5 0.184\n",
      "hero 5 0.184\n",
      "ลูกศร 5 0.184\n",
      "ทีที 5 0.184\n",
      "ก้อนก้อน 5 0.184\n",
      "อินทิเกรตลบอินฟินิตี้ 5 0.184\n",
      "inverter 5 0.184\n",
      "summation 5 0.184\n",
      "สามลบ 5 0.184\n",
      "บล็อก 5 0.184\n",
      "variance 5 0.184\n",
      "คูณศูนย์ 5 0.184\n",
      "หลักสูตร 5 0.184\n",
      "conation 5 0.184\n",
      "ลิตี้ 5 0.184\n",
      "ลบทาว 5 0.184\n",
      "เอชทีลบ 5 0.184\n",
      "สนิท 5 0.184\n",
      "reset 5 0.184\n",
      "ซีรี่ส์ 5 0.184\n",
      "coefficient 5 0.184\n",
      "สแควร์รูท 5 0.184\n",
      "เคที่ 5 0.184\n",
      "สแควรูท 5 0.184\n",
      "condition 5 0.184\n",
      "notation 5 0.184\n",
      "การ์ด 5 0.184\n",
      "alfa 5 0.184\n",
      "เจโอเมก้าคี 5 0.184\n",
      "เจโอเมก้าที 5 0.184\n",
      "อยู่ดี 5 0.184\n",
      "มารีพีท 5 0.184\n",
      "เอดี 5 0.184\n",
      "สแตน 5 0.184\n",
      "asian 5 0.184\n",
      "comedy 5 0.184\n",
      "degree 5 0.184\n",
      "เยอะกว่า 5 0.184\n",
      "บริสุทธิ์ 5 0.184\n",
      "แท่ง 5 0.184\n",
      "expectation 5 0.184\n",
      "warrent 5 0.184\n",
      "สกอร์ 5 0.184\n",
      "แคลเซียม 5 0.184\n",
      "แลมด้า 5 0.184\n",
      "theta 5 0.184\n",
      "bias 5 0.184\n",
      "หมอดู 5 0.184\n",
      "กำแพง 5 0.184\n",
      "บทความ 5 0.184\n",
      "ท้อง 5 0.184\n",
      "บรรยาย 5 0.184\n",
      "วิทยาศาสตร์ 5 0.184\n",
      "แพ็คเกจ 5 0.184\n",
      "activation 5 0.184\n",
      "หัวหน้า 5 0.184\n",
      "print 4 0.147\n",
      "จังหวะ 4 0.147\n",
      "ประกัน 4 0.147\n",
      "เลือด 4 0.147\n",
      "smart 4 0.147\n",
      "กรรมการ 4 0.147\n",
      "พัฒนา 4 0.147\n",
      "สิทธิ์ 4 0.147\n",
      "แคลคูลัส 4 0.147\n",
      "inviter 4 0.147\n",
      "contra 4 0.147\n",
      "macy 4 0.147\n",
      "office 4 0.147\n",
      "price 4 0.147\n",
      "section 4 0.147\n",
      "shop 4 0.147\n",
      "บอคอ 4 0.147\n",
      "ระลึก 4 0.147\n",
      "สามสาม 4 0.147\n",
      "อกซ์ 4 0.147\n",
      "destination 4 0.147\n",
      "factor 4 0.147\n",
      "file 4 0.147\n",
      "note 4 0.147\n",
      "test 4 0.147\n",
      "เดีย 4 0.147\n",
      "เอฟเฟกต์ 4 0.147\n",
      "canon 4 0.147\n",
      "infinite 4 0.147\n",
      "lotion 4 0.147\n",
      "renai 4 0.147\n",
      "ชนิด 4 0.147\n",
      "simulate 4 0.147\n",
      "ตอนตอน 4 0.147\n",
      "excess 4 0.147\n",
      "บอร์ด 4 0.147\n",
      "minimum 4 0.147\n",
      "programming 4 0.147\n",
      "หมวก 4 0.147\n",
      "confrim 4 0.147\n",
      "constance 4 0.147\n",
      "principle 4 0.147\n",
      "คีย์เวิร์ด 4 0.147\n",
      "เมือง 4 0.147\n",
      "เป็นเป็น 4 0.147\n",
      "business 4 0.147\n",
      "multiple 4 0.147\n",
      "ค้นหา 4 0.147\n",
      "book 4 0.147\n",
      "enter 4 0.147\n",
      "ออปติคอล 4 0.147\n",
      "เชียร์ 4 0.147\n",
      "method 4 0.147\n",
      "เลือกเลือก 4 0.147\n",
      "regent 4 0.147\n",
      "ซีเอ็กซ์ 4 0.147\n",
      "อีเอ็กซ์ 4 0.147\n",
      "แอร์ 4 0.147\n",
      "sent 4 0.147\n",
      "อัพโหลด 4 0.147\n",
      "stem 4 0.147\n",
      "อัลกอ 4 0.147\n",
      "บ๊าย 4 0.147\n",
      "หลาน 4 0.147\n",
      "จังหวัด 4 0.147\n",
      "ถล่ม 4 0.147\n",
      "ศูนย์ศูนย์ศูนย์ศูนย์ 4 0.147\n",
      "ซ้อม 4 0.147\n",
      "simat 4 0.147\n",
      "ไนท์ 4 0.147\n",
      "ลบศูนย์ 4 0.147\n",
      "หวาน 4 0.147\n",
      "setup 4 0.147\n",
      "ทริป 4 0.147\n",
      "intuition 4 0.147\n",
      "ละลาย 4 0.147\n",
      "able 4 0.147\n",
      "nature 4 0.147\n",
      "peter 4 0.147\n",
      "ซีเนียริตี้ 4 0.147\n",
      "นิทาน 4 0.147\n",
      "หลับ 4 0.147\n",
      "interpolate 4 0.147\n",
      "เป็นอยู่ 4 0.147\n",
      "กึ่งกลาง 4 0.147\n",
      "ควัน 4 0.147\n",
      "เกลียด 4 0.147\n",
      "ว่าเขียน 4 0.147\n",
      "อาร์เอ็กซ์ 4 0.147\n",
      "base 4 0.147\n",
      "กดกด 4 0.147\n",
      "ตัดตัด 4 0.147\n",
      "เจที 4 0.147\n",
      "binary 4 0.147\n",
      "สามี 4 0.147\n",
      "เอาจริง 4 0.147\n",
      "subtitle 4 0.147\n",
      "ดีใจ 4 0.147\n",
      "text 4 0.147\n",
      "ครอบ 4 0.147\n",
      "สะสม 4 0.147\n",
      "สิทธิ 4 0.147\n",
      "โปรด 4 0.147\n",
      "person 4 0.147\n",
      "ทยอย 4 0.147\n",
      "เสาร์ 4 0.147\n",
      "communication 4 0.147\n",
      "วิจารณญาณ 4 0.147\n",
      "apply 4 0.147\n",
      "แอพพลิเคชั่น 4 0.147\n",
      "พี่พี่ 4 0.147\n",
      "กำจัด 4 0.147\n",
      "ลำโพง 4 0.147\n",
      "กระโดด 4 0.147\n",
      "คอนทินิวอัสนะ 4 0.147\n",
      "อนาล็อก 4 0.147\n",
      "เศร้า 4 0.147\n",
      "เอ็นที 4 0.147\n",
      "ไทร์ 4 0.147\n",
      "คอมเพค 4 0.147\n",
      "ทะเล 4 0.147\n",
      "เกลียว 4 0.147\n",
      "แก๊ง 4 0.147\n",
      "บีวาย 4 0.147\n",
      "อินเทอร์ 4 0.147\n",
      "เอลบบี 4 0.147\n",
      "คาบไหม 4 0.147\n",
      "อะไรเนาะ 4 0.147\n",
      "เอ็กซ์แพน 4 0.147\n",
      "สปอยล์ 4 0.147\n",
      "เทคลิมิต 4 0.147\n",
      "ดีเลย์ 4 0.147\n",
      "สปีดอัพ 4 0.147\n",
      "ทีนี้ 4 0.147\n",
      "ก้าว 4 0.147\n",
      "เนื้อ 4 0.147\n",
      "แอปพลิเคชั่น 4 0.147\n",
      "discreet 4 0.147\n",
      "นิยม 4 0.147\n",
      "แซมลิ้ง 4 0.147\n",
      "โอเมก้าเอส 4 0.147\n",
      "ด่วน 4 0.147\n",
      "เอฟบี 4 0.147\n",
      "คลอด 4 0.147\n",
      "ประหลาด 4 0.147\n",
      "สปริง 4 0.147\n",
      "manipulate 4 0.147\n",
      "เงี้ยะ 4 0.147\n",
      "ป๊อบ 4 0.147\n",
      "สวิตช์ 4 0.147\n",
      "คอนวัน 4 0.147\n",
      "โปรเซส 4 0.147\n",
      "สะดวก 4 0.147\n",
      "seen 4 0.147\n",
      "shipping 4 0.147\n",
      "ครั้งอ่ะ 4 0.147\n",
      "bill 4 0.147\n",
      "เอชเจโอเมก้า 4 0.147\n",
      "dusit 4 0.147\n",
      "respond 4 0.147\n",
      "สัตว์ 4 0.147\n",
      "แม่น 4 0.147\n",
      "ยายเอ็น 4 0.147\n",
      "seri 4 0.147\n",
      "คะเอ็ม 4 0.147\n",
      "อ่ะมัน 4 0.147\n",
      "income 4 0.147\n",
      "port 4 0.147\n",
      "ไทเทิล 4 0.147\n",
      "จุดต่อ 4 0.147\n",
      "foret 4 0.147\n",
      "เป็ด 4 0.147\n",
      "ดูสไลด์ 4 0.147\n",
      "summary 4 0.147\n",
      "อินลาส 4 0.147\n",
      "keyword 4 0.147\n",
      "พีดี 4 0.147\n",
      "อะเนาะนะ 4 0.147\n",
      "ร่อน 4 0.147\n",
      "อินฟิ 4 0.147\n",
      "พิธี 4 0.147\n",
      "ศูนย์เอ็น 4 0.147\n",
      "channel 4 0.147\n",
      "ข้อไหน 4 0.147\n",
      "memory 4 0.147\n",
      "ดิรี 4 0.147\n",
      "เอซี 4 0.147\n",
      "ซ้ำซ้ำ 4 0.147\n",
      "มันคูณ 4 0.147\n",
      "package 4 0.147\n",
      "varience 4 0.147\n",
      "เอทีน 4 0.147\n",
      "เมย์ 4 0.147\n",
      "พีอียก 4 0.147\n",
      "ดื่ม 4 0.147\n",
      "คะตัว 4 0.147\n",
      "ช่องทาง 4 0.147\n",
      "อะเนาะ 4 0.147\n",
      "เอเซีย 4 0.147\n",
      "วิธีการ 4 0.147\n",
      "เฟสนะ 4 0.147\n",
      "แอมปลิจูด 4 0.147\n",
      "คาดหวัง 4 0.147\n",
      "แพทเทิร์น 4 0.147\n",
      "connection 4 0.147\n",
      "เจ้าหน้าที่ 4 0.147\n",
      "เคเค 4 0.147\n",
      "ขโมย 4 0.147\n",
      "อาชีพ 4 0.147\n",
      "ลิงก์ 4 0.147\n",
      "ศูนย์โอเมก้า 4 0.147\n",
      "สองสูตร 4 0.147\n",
      "เอกซ์เจโอเมก้า 4 0.147\n",
      "เอกเซล 4 0.147\n",
      "เอ็กซ์โอเมก้า 4 0.147\n",
      "forest 4 0.147\n",
      "เอ็กซ์เตโอเมก้า 4 0.147\n",
      "คลาย 4 0.147\n",
      "เอสเจ 4 0.147\n",
      "พอตตี้ 4 0.147\n",
      "แพทย์ 4 0.147\n",
      "หายนะ 4 0.147\n",
      "ซีรีย์ 4 0.147\n",
      "เอ็นมัน 4 0.147\n",
      "ฮัลโหล 4 0.147\n",
      "เคอะ 4 0.147\n",
      "ตังค์ 4 0.147\n",
      "เจ้าตัวเอเค 4 0.147\n",
      "สองพาย 4 0.147\n",
      "รูปฟอร์ม 4 0.147\n",
      "นึ่ง 4 0.147\n",
      "ลิ้งค์ 4 0.147\n",
      "ไซต์ 4 0.147\n",
      "outcome 4 0.147\n",
      "stat 4 0.147\n",
      "เมนู 4 0.147\n",
      "destitution 4 0.147\n",
      "histogram 4 0.147\n",
      "volume 4 0.147\n",
      "ดีเอฟ 4 0.147\n",
      "lando 4 0.147\n",
      "พอพอ 4 0.147\n",
      "บ่งบอก 4 0.147\n",
      "radiance 4 0.147\n",
      "valiant 4 0.147\n",
      "station 4 0.147\n",
      "สถิติ 4 0.147\n",
      "เซลเซียส 4 0.147\n",
      "เบี้ย 4 0.147\n",
      "เบี้ยว 4 0.147\n",
      "เปอร์เซ็น 4 0.147\n",
      "สแควร์รูทเอ็น 4 0.147\n",
      "silution 4 0.147\n",
      "intimate 4 0.147\n",
      "พอใส่ 4 0.147\n",
      "world 4 0.147\n",
      "แฟร์ 4 0.147\n",
      "ปรัชญา 4 0.147\n",
      "confidence 4 0.147\n",
      "confidential 4 0.147\n",
      "กระตุ้น 4 0.147\n",
      "จุดเก้า 4 0.147\n",
      "นิ้ว 4 0.147\n",
      "เจ็ดพัน 4 0.147\n",
      "เปิล 4 0.147\n",
      "student 4 0.147\n",
      "สมัคร 4 0.147\n",
      "แลนด์ 4 0.147\n",
      "experiment 4 0.147\n",
      "next 4 0.147\n",
      "กฎหมาย 4 0.147\n",
      "โคตรโคตร 4 0.147\n",
      "แท็ก 4 0.147\n",
      "jurney 4 0.147\n",
      "บัณฑิต 4 0.147\n",
      "พนักงาน 4 0.147\n",
      "card 4 0.147\n",
      "รีบอร์ด 4 0.147\n",
      "conmat 3 0.11\n",
      "sheet 3 0.11\n",
      "เตือน 3 0.11\n",
      "แหลม 3 0.11\n",
      "ative 3 0.11\n",
      "center 3 0.11\n",
      "dicision 3 0.11\n",
      "from 3 0.11\n",
      "machine 3 0.11\n",
      "minimize 3 0.11\n",
      "motive 3 0.11\n",
      "online 3 0.11\n",
      "premier 3 0.11\n",
      "thor 3 0.11\n",
      "นิเจอร์ 3 0.11\n",
      "dear 3 0.11\n",
      "geometric 3 0.11\n",
      "passion 3 0.11\n",
      "optional 3 0.11\n",
      "profit 3 0.11\n",
      "rear 3 0.11\n",
      "regia 3 0.11\n",
      "renier 3 0.11\n",
      "spot 3 0.11\n",
      "แปดแปด 3 0.11\n",
      "conflict 3 0.11\n",
      "optical 3 0.11\n",
      "พีพี 3 0.11\n",
      "unbound 3 0.11\n",
      "บางบาง 3 0.11\n",
      "บึ้ง 3 0.11\n",
      "ปลูก 3 0.11\n",
      "ฟ้อง 3 0.11\n",
      "อาคาร 3 0.11\n",
      "เติมเติม 3 0.11\n",
      "โบราณ 3 0.11\n",
      "แบบฟอร์ม 3 0.11\n",
      "ปีเตอร์ 3 0.11\n",
      "convention 3 0.11\n",
      "ตอบนะ 3 0.11\n",
      "สามสี่ห้า 3 0.11\n",
      "สแกน 3 0.11\n",
      "ห้ามห้าม 3 0.11\n",
      "ศูนย์ศูนย์ลบ 3 0.11\n",
      "หล่อ 3 0.11\n",
      "ไล่ไล่ 3 0.11\n",
      "orginal 3 0.11\n",
      "trip 3 0.11\n",
      "ธรรมดาธรรมดา 3 0.11\n",
      "เต้น 3 0.11\n",
      "around 3 0.11\n",
      "ทิศทาง 3 0.11\n",
      "เวกเตอร์ 3 0.11\n",
      "officie 3 0.11\n",
      "เอสเอ 3 0.11\n",
      "site 3 0.11\n",
      "pore 3 0.11\n",
      "sale 3 0.11\n",
      "บึ้ม 3 0.11\n",
      "สองสอง 3 0.11\n",
      "concrete 3 0.11\n",
      "บีเอ็มเอส 3 0.11\n",
      "ระบาย 3 0.11\n",
      "เอเอ 3 0.11\n",
      "ไหว้ 3 0.11\n",
      "กัญชา 3 0.11\n",
      "ตะวัน 3 0.11\n",
      "petple 3 0.11\n",
      "สมาชิก 3 0.11\n",
      "ริทึม 3 0.11\n",
      "เป็นฟอร์ม 3 0.11\n",
      "contrail 3 0.11\n",
      "บ๊ายบาย 3 0.11\n",
      "since 3 0.11\n",
      "สวยสวย 3 0.11\n",
      "ถนัด 3 0.11\n",
      "ตามใจ 3 0.11\n",
      "เปอร์เซนต์ 3 0.11\n",
      "regenerate 3 0.11\n",
      "บีเอ 3 0.11\n",
      "สังคม 3 0.11\n",
      "อีเอ็มเอส 3 0.11\n",
      "นิดหนึ่ง 3 0.11\n",
      "เนิน 3 0.11\n",
      "stop 3 0.11\n",
      "trade 3 0.11\n",
      "ตัดสิน 3 0.11\n",
      "ยกยก 3 0.11\n",
      "libary 3 0.11\n",
      "editor 3 0.11\n",
      "mini 3 0.11\n",
      "ขนาน 3 0.11\n",
      "ท้ายท้าย 3 0.11\n",
      "initial 3 0.11\n",
      "เดอร์ 3 0.11\n",
      "แปรทาง 3 0.11\n",
      "เอาเอา 3 0.11\n",
      "โอ้ย 3 0.11\n",
      "ช่วยเหลือ 3 0.11\n",
      "หน้าต่าง 3 0.11\n",
      "เนียน 3 0.11\n",
      "back 3 0.11\n",
      "บัตร 3 0.11\n",
      "สามสี่ 3 0.11\n",
      "เสียหาย 3 0.11\n",
      "bank 3 0.11\n",
      "persie 3 0.11\n",
      "สเปก 3 0.11\n",
      "ห้าห้า 3 0.11\n",
      "อารมณ์ 3 0.11\n",
      "analyze 3 0.11\n",
      "dance 3 0.11\n",
      "หนึ่งเอส 3 0.11\n",
      "อุตส่าห์ 3 0.11\n",
      "scaling 3 0.11\n",
      "thinking 3 0.11\n",
      "ทรัพยากร 3 0.11\n",
      "ผลิตภัณฑ์ 3 0.11\n",
      "เฉือน 3 0.11\n",
      "เอชสาม 3 0.11\n",
      "เอฟซี 3 0.11\n",
      "engine 3 0.11\n",
      "forte 3 0.11\n",
      "ลิฟต์ 3 0.11\n",
      "เหมาะ 3 0.11\n",
      "comment 3 0.11\n",
      "server 3 0.11\n",
      "กระเป๋า 3 0.11\n",
      "ยากยาก 3 0.11\n",
      "background 3 0.11\n",
      "contact 3 0.11\n",
      "detail 3 0.11\n",
      "format 3 0.11\n",
      "forward 3 0.11\n",
      "homework 3 0.11\n",
      "week 3 0.11\n",
      "คะเผื่อ 3 0.11\n",
      "สื่อสาร 3 0.11\n",
      "ไลฟ์สตรีม 3 0.11\n",
      "ไทม์ไลน์ 3 0.11\n",
      "ตื่นเต้น 3 0.11\n",
      "ปรับเปลี่ยน 3 0.11\n",
      "หนึง 3 0.11\n",
      "เบสนะ 3 0.11\n",
      "ดาวน์โหลด 3 0.11\n",
      "แล้วเนาะ 3 0.11\n",
      "พลาย 3 0.11\n",
      "สแตท 3 0.11\n",
      "ฮาร์ดแวร์ 3 0.11\n",
      "long 3 0.11\n",
      "ว่าการ 3 0.11\n",
      "อินโทร 3 0.11\n",
      "information 3 0.11\n",
      "sign 3 0.11\n",
      "ประวัติ 3 0.11\n",
      "อิมเมจ 3 0.11\n",
      "อุณหภูมิ 3 0.11\n",
      "cloud 3 0.11\n",
      "ดิฉัน 3 0.11\n",
      "นิดนิด 3 0.11\n",
      "voltage 3 0.11\n",
      "ทาวส่วน 3 0.11\n",
      "ทีเอส 3 0.11\n",
      "inter 3 0.11\n",
      "payment 3 0.11\n",
      "period 3 0.11\n",
      "มานะ 3 0.11\n",
      "สิงหา 3 0.11\n",
      "อะไรวะ 3 0.11\n",
      "โน๊ต 3 0.11\n",
      "คะสูตร 3 0.11\n",
      "โอเคโอเค 3 0.11\n",
      "คอมเพล 3 0.11\n",
      "ตาร์ 3 0.11\n",
      "บวกเจ 3 0.11\n",
      "ประมาณประมาณ 3 0.11\n",
      "ศูนย์ที 3 0.11\n",
      "เอ็กซ์โป 3 0.11\n",
      "เอเอฟ 3 0.11\n",
      "แซ่บ 3 0.11\n",
      "ที่คูณ 3 0.11\n",
      "หกหก 3 0.11\n",
      "จริงอ่ะ 3 0.11\n",
      "สามที 3 0.11\n",
      "คร่อม 3 0.11\n",
      "ทั่ง 3 0.11\n",
      "เต็มที่ 3 0.11\n",
      "พาวเวอร์ซิกแนล 3 0.11\n",
      "เอยก 3 0.11\n",
      "ควบคู่ 3 0.11\n",
      "เต็มเต็ม 3 0.11\n",
      "complete 3 0.11\n",
      "refle 3 0.11\n",
      "เน็ต 3 0.11\n",
      "ฟอร์เมชั่น 3 0.11\n",
      "อินทรา 3 0.11\n",
      "condo 3 0.11\n",
      "คะเอ็กซ์ที 3 0.11\n",
      "ดิกรี 3 0.11\n",
      "บีลบ 3 0.11\n",
      "อินตี 3 0.11\n",
      "modulation 3 0.11\n",
      "recontract 3 0.11\n",
      "เอ็กซี 3 0.11\n",
      "local 3 0.11\n",
      "ซีโร่ 3 0.11\n",
      "ลูชั่น 3 0.11\n",
      "เอฟเอฟ 3 0.11\n",
      "เอฟเอส 3 0.11\n",
      "แบนด์ 3 0.11\n",
      "โอเมก้าบี 3 0.11\n",
      "โคลง 3 0.11\n",
      "มีเดโม่ 3 0.11\n",
      "เอฟศูนย์ 3 0.11\n",
      "หยุดนิ่ง 3 0.11\n",
      "เคลื่อน 3 0.11\n",
      "เป็นเดโม่ 3 0.11\n",
      "selective 3 0.11\n",
      "ฟรีโดเมน 3 0.11\n",
      "ฟิลลิ่ง 3 0.11\n",
      "อนุกรม 3 0.11\n",
      "ippon 3 0.11\n",
      "ลดทอน 3 0.11\n",
      "เคนะ 3 0.11\n",
      "ฟรีเควนซี่โดเมน 3 0.11\n",
      "dome 3 0.11\n",
      "ซีเคว้น 3 0.11\n",
      "เอฟที 3 0.11\n",
      "ไทม์โนเมน 3 0.11\n",
      "lohas 3 0.11\n",
      "คูณกันธรรมดา 3 0.11\n",
      "platform 3 0.11\n",
      "practical 3 0.11\n",
      "suter 3 0.11\n",
      "สูงต่ำ 3 0.11\n",
      "ป้าย 3 0.11\n",
      "เช่า 3 0.11\n",
      "ควบคุม 3 0.11\n",
      "นันท์ 3 0.11\n",
      "ลิขสิทธิ์ 3 0.11\n",
      "อสูร 3 0.11\n",
      "คอร์สนะ 3 0.11\n",
      "ชั่ง 3 0.11\n",
      "ลองพอต 3 0.11\n",
      "เมเจอร์ 3 0.11\n",
      "เอชพี 3 0.11\n",
      "เอ็มเอ็ม 3 0.11\n",
      "แคนซี่ 3 0.11\n",
      "lily 3 0.11\n",
      "strength 3 0.11\n",
      "เฟอร์ 3 0.11\n",
      "ยักษ์ 3 0.11\n",
      "แกว่ง 3 0.11\n",
      "กรุ๊ป 3 0.11\n",
      "คอมมินชั่น 3 0.11\n",
      "ฟีเรน 3 0.11\n",
      "สบายเคส 3 0.11\n",
      "อินทราส 3 0.11\n",
      "สื่อ 3 0.11\n",
      "อยู่เนาะนะ 3 0.11\n",
      "good 3 0.11\n",
      "คอมโพส 3 0.11\n",
      "ทีทีที 3 0.11\n",
      "integra 3 0.11\n",
      "คอร์สพาย 3 0.11\n",
      "สัญญาณซิกนัม 3 0.11\n",
      "คอนไซน์ 3 0.11\n",
      "คอร์ท 3 0.11\n",
      "ดิสที 3 0.11\n",
      "คอสต์ 3 0.11\n",
      "ไปหาร 3 0.11\n",
      "บาร์ 3 0.11\n",
      "มะลิ 3 0.11\n",
      "ทีนึง 3 0.11\n",
      "ชีลบ 3 0.11\n",
      "ดิคิด 3 0.11\n",
      "ดึงดึง 3 0.11\n",
      "ดีเอ็กซ์ 3 0.11\n",
      "เอ้าท์ 3 0.11\n",
      "คะควร 3 0.11\n",
      "สัมประสิทธิ์คูณ 3 0.11\n",
      "อิ่ม 3 0.11\n",
      "เอ็นนะ 3 0.11\n",
      "เอ็นดู 3 0.11\n",
      "พี่เอ็น 3 0.11\n",
      "กับอิมเพ้า 3 0.11\n",
      "ทุกข์ 3 0.11\n",
      "imagine 3 0.11\n",
      "คอนสแตนท์ 3 0.11\n",
      "คอเลชั่น 3 0.11\n",
      "เทมเพลท 3 0.11\n",
      "พรีเซนต์ตัว 3 0.11\n",
      "แวร์ 3 0.11\n",
      "ปาร์ตี้ 3 0.11\n",
      "คะแบบ 3 0.11\n",
      "integration 3 0.11\n",
      "อินทิเกต 3 0.11\n",
      "แฟชั่น 3 0.11\n",
      "โปรดักส์ 3 0.11\n",
      "ประสบการณ์ 3 0.11\n",
      "เพราะฉนั้น 3 0.11\n",
      "ออกแบบ 3 0.11\n",
      "ดีเอสที 3 0.11\n",
      "เพล็กซ์ 3 0.11\n",
      "ฮาโมนิก 3 0.11\n",
      "อินทิเกรตก้อน 3 0.11\n",
      "เคมัน 3 0.11\n",
      "furia ซีรีส์ 3 0.11\n",
      "อินทิ 3 0.11\n",
      "sericin 3 0.11\n",
      "สเปกตรัม 3 0.11\n",
      "สเปคต้า 3 0.11\n",
      "เป้า 3 0.11\n",
      "ใช่ป่ะ 3 0.11\n",
      "summit 3 0.11\n",
      "furie 3 0.11\n",
      "เลอร์ 3 0.11\n",
      "เอเคน 3 0.11\n",
      "อินทิเกรตลบ 3 0.11\n",
      "convert 3 0.11\n",
      "ลบเป็น 3 0.11\n",
      "เอ็กซ์ซี 3 0.11\n",
      "พีเค 3 0.11\n",
      "เอลบสาม 3 0.11\n",
      "cost 3 0.11\n",
      "แพร์ 3 0.11\n",
      "seventy 3 0.11\n",
      "คู่แปลง 3 0.11\n",
      "ออริตี้ 3 0.11\n",
      "คะจริงจริง 3 0.11\n",
      "ตกราฟ 3 0.11\n",
      "กดเครื่อง 3 0.11\n",
      "คะโอเค 3 0.11\n",
      "fori 3 0.11\n",
      "เมกาคูณ 3 0.11\n",
      "predict 3 0.11\n",
      "differentation 3 0.11\n",
      "เคชั่น 3 0.11\n",
      "วุ่นวาย 3 0.11\n",
      "เพอร์ตี้ 3 0.11\n",
      "แมนจู 3 0.11\n",
      "conjugate 3 0.11\n",
      "คาบเนี่ย 3 0.11\n",
      "เชียว 3 0.11\n",
      "ปุ้ย 3 0.11\n",
      "คาบเดียว 3 0.11\n",
      "คาบเอ็น 3 0.11\n",
      "ดีรีท 3 0.11\n",
      "ฮัลโหลฮัลโหล 3 0.11\n",
      "เอสี่ 3 0.11\n",
      "context 3 0.11\n",
      "เป็นสอง 3 0.11\n",
      "กาแฟ 3 0.11\n",
      "ดับเบิ้ลยู 3 0.11\n",
      "รีพีท 3 0.11\n",
      "เบิ้ล 3 0.11\n",
      "ด้วยซ้ำ 3 0.11\n",
      "เมกานะ 3 0.11\n",
      "เอ็กซ์เอเอ็น 3 0.11\n",
      "เอ็นหาร 3 0.11\n",
      "ชั่ว 3 0.11\n",
      "that 3 0.11\n",
      "comic 3 0.11\n",
      "เนชั่น 3 0.11\n",
      "แว่น 3 0.11\n",
      "แก๊ส 3 0.11\n",
      "แปลกใจ 3 0.11\n",
      "commority 3 0.11\n",
      "operate 3 0.11\n",
      "epica 3 0.11\n",
      "rotation 3 0.11\n",
      "tation 3 0.11\n",
      "ครอบครัว 3 0.11\n",
      "expiration 3 0.11\n",
      "love 3 0.11\n",
      "waline 3 0.11\n",
      "ตรงไป 3 0.11\n",
      "conditional 3 0.11\n",
      "varient 3 0.11\n",
      "กระจุก 3 0.11\n",
      "เคมี 3 0.11\n",
      "โควา 3 0.11\n",
      "correlation 3 0.11\n",
      "ล้าง 3 0.11\n",
      "เป็นลีเดีย 3 0.11\n",
      "uniform 3 0.11\n",
      "หลอด 3 0.11\n",
      "แข็ง 3 0.11\n",
      "marine 3 0.11\n",
      "orient 3 0.11\n",
      "parity 3 0.11\n",
      "โตเซียน 3 0.11\n",
      "บีบี 3 0.11\n",
      "land 3 0.11\n",
      "community 3 0.11\n",
      "percent 3 0.11\n",
      "เมนูรี 3 0.11\n",
      "sata 3 0.11\n",
      "simulation 3 0.11\n",
      "city 3 0.11\n",
      "heaven 3 0.11\n",
      "parametric 3 0.11\n",
      "vision 3 0.11\n",
      "armat 3 0.11\n",
      "oaty 3 0.11\n",
      "ก้อย 3 0.11\n",
      "continental 3 0.11\n",
      "ประธาน 3 0.11\n",
      "เบเลี่ยน 3 0.11\n",
      "เทียม 3 0.11\n",
      "เอสดี 3 0.11\n",
      "ตะกอน 3 0.11\n",
      "เสิร์ฟ 3 0.11\n",
      "เอ็มเอ 3 0.11\n",
      "คาดคิด 3 0.11\n",
      "ยุโรป 3 0.11\n",
      "รีเจ็ค 3 0.11\n",
      "บังเอิญ 3 0.11\n",
      "ลำบาก 3 0.11\n",
      "หว่า 3 0.11\n",
      "หนังสือพิมพ์ 3 0.11\n",
      "hacking 3 0.11\n",
      "packing 3 0.11\n",
      "ขั้นตอน 3 0.11\n",
      "สกรีน 3 0.11\n",
      "label 3 0.11\n",
      "ตื่น 3 0.11\n",
      "iron 3 0.11\n",
      "เอ็มอี 3 0.11\n",
      "paper 3 0.11\n",
      "ซ้ำซ้อน 3 0.11\n",
      "cant 3 0.11\n",
      "มงคล 3 0.11\n",
      "cast 3 0.11\n",
      "ซื้อขาย 3 0.11\n",
      "ยาวยาว 3 0.11\n",
      "ไทล์ 3 0.11\n",
      "กรุงเทพ 3 0.11\n",
      "ซอฟต์แวร์ 3 0.11\n",
      "แอคชั่น 3 0.11\n",
      "เทสต์ 3 0.11\n",
      "hamtaro 3 0.11\n",
      "เบนลี 3 0.11\n",
      "element 3 0.11\n",
      "spit 3 0.11\n",
      "หยุดหยุด 3 0.11\n",
      "expro 3 0.11\n",
      "fade 3 0.11\n",
      "โยกสล็อต 3 0.11\n",
      "reword 3 0.11\n",
      "esperon 3 0.11\n",
      "ยูซีซี 3 0.11\n",
      "clip 2 0.073\n",
      "concert 2 0.073\n",
      "statement 2 0.073\n",
      "ถั่ว 2 0.073\n",
      "บัญชี 2 0.073\n",
      "ผู้คน 2 0.073\n",
      "ลดหลั่น 2 0.073\n",
      "หลบหลบ 2 0.073\n",
      "อีสาน 2 0.073\n",
      "อุ่น 2 0.073\n",
      "ใครใคร 2 0.073\n",
      "dison 2 0.073\n",
      "location 2 0.073\n",
      "tive 2 0.073\n",
      "คอนเทน 2 0.073\n",
      "ซิทีฟ 2 0.073\n",
      "ซึ้ง 2 0.073\n",
      "ตั้ม 2 0.073\n",
      "รวยรวย 2 0.073\n",
      "ออกซิทีฟ 2 0.073\n",
      "อิสาน 2 0.073\n",
      "โจทก์ 2 0.073\n",
      "anager 2 0.073\n",
      "asic 2 0.073\n",
      "band 2 0.073\n",
      "baro 2 0.073\n",
      "interent 2 0.073\n",
      "story 2 0.073\n",
      "ture 2 0.073\n",
      "กิโล 2 0.073\n",
      "ซิโก้ 2 0.073\n",
      "บ้าบอคอ 2 0.073\n",
      "มินิหาย 2 0.073\n",
      "สามเอ็น 2 0.073\n",
      "อาแซด 2 0.073\n",
      "เอ็นจีเค 2 0.073\n",
      "แอมโร 2 0.073\n",
      "rena 2 0.073\n",
      "ดิชั่น 2 0.073\n",
      "รูปภาพ 2 0.073\n",
      "สว่าง 2 0.073\n",
      "อนุบาล 2 0.073\n",
      "เอ็นพี 2 0.073\n",
      "แฮปปี้ 2 0.073\n",
      "ematrix 2 0.073\n",
      "feasible 2 0.073\n",
      "pedia 2 0.073\n",
      "redial 2 0.073\n",
      "reit 2 0.073\n",
      "resin 2 0.073\n",
      "ขยับขยาย 2 0.073\n",
      "ทศนิยม 2 0.073\n",
      "นิตี 2 0.073\n",
      "ลีเนียร์ 2 0.073\n",
      "เคลอง 2 0.073\n",
      "conner 2 0.073\n",
      "offical 2 0.073\n",
      "recipe 2 0.073\n",
      "zone 2 0.073\n",
      "คอนกรีต 2 0.073\n",
      "พื้น 2 0.073\n",
      "ลากลาก 2 0.073\n",
      "ลูกบาศก์ 2 0.073\n",
      "มนุษย์ 2 0.073\n",
      "สปอย์ 2 0.073\n",
      "สำเร็จรูป 2 0.073\n",
      "สเตป 2 0.073\n",
      "ออเดอร์ 2 0.073\n",
      "อิอิ 2 0.073\n",
      "contest 2 0.073\n",
      "excite 2 0.073\n",
      "standart 2 0.073\n",
      "valente 2 0.073\n",
      "คุณเขียน 2 0.073\n",
      "บารมี 2 0.073\n",
      "รองรับ 2 0.073\n",
      "รูปร่าง 2 0.073\n",
      "สแลค 2 0.073\n",
      "disband 2 0.073\n",
      "บอกบอก 2 0.073\n",
      "เครื่องเครื่อง 2 0.073\n",
      "ปุ๊ป 2 0.073\n",
      "ลูกน้อง 2 0.073\n",
      "marib 2 0.073\n",
      "valable 2 0.073\n",
      "เบสิคโซลูชั่น 2 0.073\n",
      "exim 2 0.073\n",
      "star 2 0.073\n",
      "คอนเวิส 2 0.073\n",
      "ตรึง 2 0.073\n",
      "บวกบวก 2 0.073\n",
      "เป็นลอง 2 0.073\n",
      "deda 2 0.073\n",
      "motivation 2 0.073\n",
      "คีย์คีย์ 2 0.073\n",
      "จีเอ 2 0.073\n",
      "บีเอส 2 0.073\n",
      "อ่ะที 2 0.073\n",
      "lion 2 0.073\n",
      "mnet 2 0.073\n",
      "บิดา 2 0.073\n",
      "ว่าย 2 0.073\n",
      "หนาว 2 0.073\n",
      "เลี่ยน 2 0.073\n",
      "ไวท์ 2 0.073\n",
      "ไอโซ 2 0.073\n",
      "contrace 2 0.073\n",
      "สิบสอง 2 0.073\n",
      "amparo 2 0.073\n",
      "inspire 2 0.073\n",
      "sopop 2 0.073\n",
      "ออฟติคอล 2 0.073\n",
      "อีซี่ 2 0.073\n",
      "เยี่ยม 2 0.073\n",
      "โอเควัน 2 0.073\n",
      "evolution 2 0.073\n",
      "masi 2 0.073\n",
      "meet 2 0.073\n",
      "soft 2 0.073\n",
      "wordpress 2 0.073\n",
      "ปอนด์ 2 0.073\n",
      "เลขสาม 2 0.073\n",
      "เอกสาม 2 0.073\n",
      "super 2 0.073\n",
      "เตะตัว 2 0.073\n",
      "เท็จ 2 0.073\n",
      "เอชสอง 2 0.073\n",
      "เอสสาม 2 0.073\n",
      "ประทาน 2 0.073\n",
      "เดชั่น 2 0.073\n",
      "เด็ดขาด 2 0.073\n",
      "เต็มอ่ะ 2 0.073\n",
      "เปอร์ 2 0.073\n",
      "แก้ว 2 0.073\n",
      "โป้ง 2 0.073\n",
      "modification 2 0.073\n",
      "teaser 2 0.073\n",
      "มิ่ง 2 0.073\n",
      "หายใจ 2 0.073\n",
      "อาหัว 2 0.073\n",
      "mario 2 0.073\n",
      "ดีเจ 2 0.073\n",
      "ที่สุดอ่ะ 2 0.073\n",
      "พี่น้อง 2 0.073\n",
      "โอเคคุณ 2 0.073\n",
      "many 2 0.073\n",
      "solve 2 0.073\n",
      "อินเทอร์เน็ต 2 0.073\n",
      "inside 2 0.073\n",
      "กระสุน 2 0.073\n",
      "ซิมเพจ 2 0.073\n",
      "ลอกลอก 2 0.073\n",
      "ซีพี 2 0.073\n",
      "อึ้ง 2 0.073\n",
      "คอนเน็ต 2 0.073\n",
      "people 2 0.073\n",
      "programme 2 0.073\n",
      "พีเจอร์ 2 0.073\n",
      "สับเซต 2 0.073\n",
      "สามเอ็กซ์ 2 0.073\n",
      "อะตอม 2 0.073\n",
      "เจอร์ 2 0.073\n",
      "เออี 2 0.073\n",
      "eder 2 0.073\n",
      "ปรีดี 2 0.073\n",
      "แอนนา 2 0.073\n",
      "amazing 2 0.073\n",
      "eden 2 0.073\n",
      "ตรัสรู้ 2 0.073\n",
      "สวรรค์ 2 0.073\n",
      "หล่อน 2 0.073\n",
      "เคลียร์ 2 0.073\n",
      "เชาว์ 2 0.073\n",
      "เอสไอ 2 0.073\n",
      "black 2 0.073\n",
      "train 2 0.073\n",
      "ลิเก 2 0.073\n",
      "brain 2 0.073\n",
      "ปริมาตร 2 0.073\n",
      "ไมค์ 2 0.073\n",
      "found 2 0.073\n",
      "sure 2 0.073\n",
      "titer 2 0.073\n",
      "คลิปที่ 2 0.073\n",
      "คล้ายคล้าย 2 0.073\n",
      "เป็นสาม 2 0.073\n",
      "แดนซ์ 2 0.073\n",
      "anime 2 0.073\n",
      "sover 2 0.073\n",
      "state 2 0.073\n",
      "vaio 2 0.073\n",
      "เซอร์ 2 0.073\n",
      "เดี๋ยวถ้า 2 0.073\n",
      "evolutionary 2 0.073\n",
      "คนละ 2 0.073\n",
      "เกริ่น 2 0.073\n",
      "เท็ม 2 0.073\n",
      "เอฟเฟก 2 0.073\n",
      "conization 2 0.073\n",
      "nisi 2 0.073\n",
      "ดินสอ 2 0.073\n",
      "หน้าหน้า 2 0.073\n",
      "หลักฐาน 2 0.073\n",
      "hybrid 2 0.073\n",
      "นิสิต 2 0.073\n",
      "activity 2 0.073\n",
      "extar 2 0.073\n",
      "เชอร์ 2 0.073\n",
      "เบียด 2 0.073\n",
      "เป็นห่วง 2 0.073\n",
      "clap 2 0.073\n",
      "quit 2 0.073\n",
      "พาร์ทนะ 2 0.073\n",
      "วิดีโอ 2 0.073\n",
      "แน่น 2 0.073\n",
      "กลิ่น 2 0.073\n",
      "คงคง 2 0.073\n",
      "คอนเสิร์ต 2 0.073\n",
      "น้องน้อง 2 0.073\n",
      "ล่วงหน้า 2 0.073\n",
      "อังคาร 2 0.073\n",
      "pressing 2 0.073\n",
      "กูเกิล 2 0.073\n",
      "นะจารย์ 2 0.073\n",
      "อะไรสิ 2 0.073\n",
      "เซิ้ง 2 0.073\n",
      "intro 2 0.073\n",
      "reference 2 0.073\n",
      "ถัดไป 2 0.073\n",
      "สบายสบาย 2 0.073\n",
      "deep 2 0.073\n",
      "differin 2 0.073\n",
      "movie 2 0.073\n",
      "ก็สไลด์ 2 0.073\n",
      "ดิฟพรีด 2 0.073\n",
      "อินฟอร์เมชั่น 2 0.073\n",
      "เซ็นเซอร์ 2 0.073\n",
      "food 2 0.073\n",
      "noice 2 0.073\n",
      "noise 2 0.073\n",
      "ประสิทธิภาพ 2 0.073\n",
      "ม้วน 2 0.073\n",
      "ยึกยัก 2 0.073\n",
      "dimension 2 0.073\n",
      "คอนทินิวซิกแนล 2 0.073\n",
      "คอนทินิวอัสไทม์ซิกแนล 2 0.073\n",
      "รีไทม์ 2 0.073\n",
      "เอฟซีลอน 2 0.073\n",
      "เอ็กซ์วาย 2 0.073\n",
      "โคออดิเนต 2 0.073\n",
      "อาสา 2 0.073\n",
      "ดิฟครีทไทม์ 2 0.073\n",
      "โควต้า 2 0.073\n",
      "คะเอฟ 2 0.073\n",
      "เมกาที 2 0.073\n",
      "แอบโซลูท 2 0.073\n",
      "เอ็กซ์พี 2 0.073\n",
      "เจ็ดคูณ 2 0.073\n",
      "เอลบปี 2 0.073\n",
      "ไทรน์ 2 0.073\n",
      "ฟังก์ชันฟังก์ชัน 2 0.073\n",
      "สตรี 2 0.073\n",
      "อ่ะจารย์ 2 0.073\n",
      "เล่นเล่น 2 0.073\n",
      "แอสซู 2 0.073\n",
      "โททัล 2 0.073\n",
      "ทียก 2 0.073\n",
      "พอร์ต 2 0.073\n",
      "พาเวอร์ 2 0.073\n",
      "ศูนย์ปุ๊บก้อน 2 0.073\n",
      "สองแอล 2 0.073\n",
      "เอเนอ 2 0.073\n",
      "ขัดขัด 2 0.073\n",
      "ทีดี 2 0.073\n",
      "นิสัย 2 0.073\n",
      "พอดีเนาะ 2 0.073\n",
      "ล้อเลียน 2 0.073\n",
      "อภัย 2 0.073\n",
      "อีเดน 2 0.073\n",
      "แอนตี้ 2 0.073\n",
      "ทรานส์ฟอร์เมชั่น 2 0.073\n",
      "พีลบ 2 0.073\n",
      "วัตถุ 2 0.073\n",
      "อัสนะ 2 0.073\n",
      "คีย์ลบ 2 0.073\n",
      "เอสต้า 2 0.073\n",
      "infity 2 0.073\n",
      "ถูกหาร 2 0.073\n",
      "มาเลท 2 0.073\n",
      "ทำทาน 2 0.073\n",
      "ปรึกษา 2 0.073\n",
      "ถูกเปล่า 2 0.073\n",
      "โทษโทษ 2 0.073\n",
      "conus 2 0.073\n",
      "ดิสคอร์ท 2 0.073\n",
      "ปลั๊ก 2 0.073\n",
      "เฟรม 2 0.073\n",
      "โคแลต 2 0.073\n",
      "flexible 2 0.073\n",
      "นะแซม 2 0.073\n",
      "บ้านบ้าน 2 0.073\n",
      "พิกเซล 2 0.073\n",
      "ยุ่งยาก 2 0.073\n",
      "ccet 2 0.073\n",
      "คัฟเวอร์ 2 0.073\n",
      "อิมเพ้า เทรน 2 0.073\n",
      "แบรนด์ลิมิต 2 0.073\n",
      "แมกซิมัม 2 0.073\n",
      "แม็กซิ 2 0.073\n",
      "กิโลเฮิร์ต 2 0.073\n",
      "เอเลียส 2 0.073\n",
      "แม็กซิมั่ม 2 0.073\n",
      "คอร์สโอเมก้า 2 0.073\n",
      "ลดลด 2 0.073\n",
      "แชมป์ 2 0.073\n",
      "ออริจินอล 2 0.073\n",
      "เพี้ยน 2 0.073\n",
      "มาร์ค 2 0.073\n",
      "stage 2 0.073\n",
      "คลูชั่น 2 0.073\n",
      "คุณอลัน 2 0.073\n",
      "นะฟิลเตอร์ 2 0.073\n",
      "เจ้าของ 2 0.073\n",
      "เอาเป็นว่า 2 0.073\n",
      "แอมป์ 2 0.073\n",
      "คะวายเอ็น 2 0.073\n",
      "อเวท 2 0.073\n",
      "เรสปอนท์ 2 0.073\n",
      "แอพพลาย 2 0.073\n",
      "computation 2 0.073\n",
      "ซีแพน 2 0.073\n",
      "อ่ะดู 2 0.073\n",
      "เกทคูณ 2 0.073\n",
      "python 2 0.073\n",
      "พาร์ทพาร์ท 2 0.073\n",
      "hiren 2 0.073\n",
      "impure 2 0.073\n",
      "คูณตัว 2 0.073\n",
      "ถัดถัด 2 0.073\n",
      "อุปกรณ์ 2 0.073\n",
      "jumping 2 0.073\n",
      "espn 2 0.073\n",
      "henry 2 0.073\n",
      "frage 2 0.073\n",
      "impulse 2 0.073\n",
      "move 2 0.073\n",
      "กับคูณ 2 0.073\n",
      "ลบเจอ 2 0.073\n",
      "แนวทาง 2 0.073\n",
      "ได้ใจ 2 0.073\n",
      "mobile 2 0.073\n",
      "อันี้ 2 0.073\n",
      "เอสเอส 2 0.073\n",
      "โครงมัน 2 0.073\n",
      "france 2 0.073\n",
      "prince 2 0.073\n",
      "fare 2 0.073\n",
      "โลพา 2 0.073\n",
      "ocean 2 0.073\n",
      "คลับ 2 0.073\n",
      "เอิ่ม 2 0.073\n",
      "ไฟนอล 2 0.073\n",
      "lens 2 0.073\n",
      "คริส 2 0.073\n",
      "คอนฟิเด้นซ์ 2 0.073\n",
      "ประมาท 2 0.073\n",
      "หมดแล้ว 2 0.073\n",
      "มารี่ 2 0.073\n",
      "เชี่ยวชาญ 2 0.073\n",
      "เร่ง 2 0.073\n",
      "เอ็กซ์ทีน 2 0.073\n",
      "แถวแถว 2 0.073\n",
      "พี่เอ็กซ์ 2 0.073\n",
      "ฟังก์ 2 0.073\n",
      "เจ้าตัวไซน์ 2 0.073\n",
      "ไทน์ 2 0.073\n",
      "into 2 0.073\n",
      "ฟังก์ชันหน้าตา 2 0.073\n",
      "เปรี้ยว 2 0.073\n",
      "sting 2 0.073\n",
      "เจอฟังก์ชั่น 2 0.073\n",
      "จัมปิ้ง 2 0.073\n",
      "เอพี 2 0.073\n",
      "คะขอ 2 0.073\n",
      "คะโอ 2 0.073\n",
      "สิ้นสุด 2 0.073\n",
      "อินทิเกรตศูนย์ 2 0.073\n",
      "ดิสครีด 2 0.073\n",
      "พี่เอ็ม 2 0.073\n",
      "serene 2 0.073\n",
      "คาบคาบ 2 0.073\n",
      "elementary 2 0.073\n",
      "ดิฟฟี 2 0.073\n",
      "รีเฟรซ 2 0.073\n",
      "นิติ 2 0.073\n",
      "พลอตรูป 2 0.073\n",
      "รีสอร์ท 2 0.073\n",
      "ลองคอต 2 0.073\n",
      "กันยา 2 0.073\n",
      "ทุ่ม 2 0.073\n",
      "เอกอน 2 0.073\n",
      "โอเคเนาะนะ 2 0.073\n",
      "diffre 2 0.073\n",
      "จำสมบัติ 2 0.073\n",
      "บทเรียน 2 0.073\n",
      "ไม่รู้ 2 0.073\n",
      "คอลัมน์ 2 0.073\n",
      "ดิฟครีดเนาะ 2 0.073\n",
      "alive 2 0.073\n",
      "การคูณ 2 0.073\n",
      "ตัวเอ 2 0.073\n",
      "เอวา 2 0.073\n",
      "ไอจี 2 0.073\n",
      "เป็นไซน์ 2 0.073\n",
      "เอ็กซ์เอ็นลบ 2 0.073\n",
      "เอ็นศูนย์คูณ 2 0.073\n",
      "เอ็นเอ็กซ์ 2 0.073\n",
      "คอโซ่ 2 0.073\n",
      "ซ่อม 2 0.073\n",
      "เบอรี่ 2 0.073\n",
      "superposition 2 0.073\n",
      "บีมัน 2 0.073\n",
      "เคคุณ 2 0.073\n",
      "extent 2 0.073\n",
      "respone 2 0.073\n",
      "vity 2 0.073\n",
      "กระดาน 2 0.073\n",
      "ซุปเปอร์โพซิชั่น 2 0.073\n",
      "เมชั่น 2 0.073\n",
      "ซำซำ 2 0.073\n",
      "ไหนอ่ะ 2 0.073\n",
      "คูณสอง 2 0.073\n",
      "เจ้าตัวตัว 2 0.073\n",
      "โทรที 2 0.073\n",
      "ว่าง่าย 2 0.073\n",
      "เผื่อเผื่อ 2 0.073\n",
      "เอกเอ็ม 2 0.073\n",
      "ขอบเขต 2 0.073\n",
      "แอลฟ่า 2 0.073\n",
      "front 2 0.073\n",
      "collation 2 0.073\n",
      "commotion 2 0.073\n",
      "cool 2 0.073\n",
      "ตอบเอ 2 0.073\n",
      "retime 2 0.073\n",
      "ซัมเมชั่น 2 0.073\n",
      "สั่น 2 0.073\n",
      "connie 2 0.073\n",
      "reality 2 0.073\n",
      "ดิฟครีด 2 0.073\n",
      "ปอปเปอร์ตี้ 2 0.073\n",
      "identity 2 0.073\n",
      "คอนเวิร์ค 2 0.073\n",
      "คอนโง 2 0.073\n",
      "ตัวยูที 2 0.073\n",
      "กราฟมัน 2 0.073\n",
      "คะเอเป็น 2 0.073\n",
      "ทาวล์ 2 0.073\n",
      "ลบบี 2 0.073\n",
      "เอเอ็กซ์เอ็น 2 0.073\n",
      "คอนโงกัน 2 0.073\n",
      "คะคีย์ 2 0.073\n",
      "communion 2 0.073\n",
      "นวลูชั่น 2 0.073\n",
      "อินทิเกรท 2 0.073\n",
      "privacy 2 0.073\n",
      "คอนไทม์ 2 0.073\n",
      "คะอันี้ 2 0.073\n",
      "พรีดิค 2 0.073\n",
      "ดอทโปรดัก 2 0.073\n",
      "ดารา 2 0.073\n",
      "เอสทีคูณ 2 0.073\n",
      "เอ็กซ์โปร์ 2 0.073\n",
      "แอลทีไอ 2 0.073\n",
      "fuwa 2 0.073\n",
      "คอนเซ็ปต์ 2 0.073\n",
      "คะสมการ 2 0.073\n",
      "สองโอเมก้า 2 0.073\n",
      "ฮอร์โมน 2 0.073\n",
      "ฮาร์มอนิค 2 0.073\n",
      "minary 2 0.073\n",
      "พรีเซนต์สัญญาณ 2 0.073\n",
      "กลับกลับ 2 0.073\n",
      "พี่เคน 2 0.073\n",
      "เคลบเอ็น 2 0.073\n",
      "เมสเสจ 2 0.073\n",
      "ทีดีที 2 0.073\n",
      "สัมประสิทธ์ 2 0.073\n",
      "อะเค 2 0.073\n",
      "xpro 2 0.073\n",
      "ปริ้นท์ 2 0.073\n",
      "เป็นอีเว่น 2 0.073\n",
      "เอลบเคคอน 2 0.073\n",
      "เอ็นอะ 2 0.073\n",
      "ไลน์สเปคต้า 2 0.073\n",
      "สถานการณ์ 2 0.073\n",
      "เทียบเคียง 2 0.073\n",
      "ถ้วน 2 0.073\n",
      "พีคตรง 2 0.073\n",
      "ศูน์ 2 0.073\n",
      "องศา 2 0.073\n",
      "dice 2 0.073\n",
      "สเปค 2 0.073\n",
      "อาจาย์ 2 0.073\n",
      "isis 2 0.073\n",
      "spectra 2 0.073\n",
      "สถาน 2 0.073\n",
      "เจเคโอเมก้าศูนย์ 2 0.073\n",
      "เรี่ย 2 0.073\n",
      "บวกไซน์ 2 0.073\n",
      "สเต็ก 2 0.073\n",
      "สเปน 2 0.073\n",
      "เคโอเมก้า 2 0.073\n",
      "พี่เอ 2 0.073\n",
      "connetion 2 0.073\n",
      "คอนเวิร์ต 2 0.073\n",
      "อินฟีตี้ 2 0.073\n",
      "รถไฟ 2 0.073\n",
      "เกร็ด 2 0.073\n",
      "กำลังคูณ 2 0.073\n",
      "คร่าวคร่าวนะ 2 0.073\n",
      "คอมโพเน้นต์ 2 0.073\n",
      "post 2 0.073\n",
      "ก็อปปี้ 2 0.073\n",
      "เออเร่อ 2 0.073\n",
      "เอเชีย 2 0.073\n",
      "disco 2 0.073\n",
      "บีบอย 2 0.073\n",
      "fiance 2 0.073\n",
      "ที่มา 2 0.073\n",
      "คลินิก 2 0.073\n",
      "คะออน 2 0.073\n",
      "transom 2 0.073\n",
      "เดี๋ยวอ่าน 2 0.073\n",
      "ไทม์โดเมนนะ 2 0.073\n",
      "conia 2 0.073\n",
      "connes 2 0.073\n",
      "ครัว 2 0.073\n",
      "ซิงเหมือน 2 0.073\n",
      "ปลุก 2 0.073\n",
      "อัลฟาลบ 2 0.073\n",
      "แอลฟาลบ 2 0.073\n",
      "furias 2 0.073\n",
      "ซูเกต 2 0.073\n",
      "เกรต 2 0.073\n",
      "เอาไป 2 0.073\n",
      "อินซิตี้ 2 0.073\n",
      "อินฟรีตี้ 2 0.073\n",
      "เอสเจโอเมก้า 2 0.073\n",
      "adia 2 0.073\n",
      "โอเมก้าโอเมก้า 2 0.073\n",
      "take 2 0.073\n",
      "เดลต้า โอเมก้า 2 0.073\n",
      "เอ็มที 2 0.073\n",
      "เดิมคูณ 2 0.073\n",
      "คอนโดชั่น 2 0.073\n",
      "เขาอ่ะ 2 0.073\n",
      "บวกโอเมก้า 2 0.073\n",
      "ลบโอเมก้า 2 0.073\n",
      "public 2 0.073\n",
      "ง่ายง่ายเนาะนะ 2 0.073\n",
      "ที่ดิน 2 0.073\n",
      "mary 2 0.073\n",
      "เดี๋ยวเดียว 2 0.073\n",
      "expore 2 0.073\n",
      "symetry 2 0.073\n",
      "ฟีเรนซี 2 0.073\n",
      "ศูนย์เฉย 2 0.073\n",
      "องค์การ 2 0.073\n",
      "โพรเสส 2 0.073\n",
      "อีพี 2 0.073\n",
      "fairy 2 0.073\n",
      "หักล้าง 2 0.073\n",
      "เออตัว 2 0.073\n",
      "ดิฟฟริน 2 0.073\n",
      "ดิสครีทไทม์ซิกเนล 2 0.073\n",
      "ฟูเรีย 2 0.073\n",
      "เทรน 2 0.073\n",
      "ตัวโอเมก้า 2 0.073\n",
      "เทียบเทียบ 2 0.073\n",
      "ซ้ำซ้ำกัน 2 0.073\n",
      "อิมพอร์ต 2 0.073\n",
      "สัมภาษณ์ 2 0.073\n",
      "อะไรเนาะนะ 2 0.073\n",
      "เออาร์ 2 0.073\n",
      "เอาตัว 2 0.073\n",
      "อาร์เอ็น 2 0.073\n",
      "เอ็น คูณ 2 0.073\n",
      "traction 2 0.073\n",
      "ล็อต 2 0.073\n",
      "died 2 0.073\n",
      "ดูสูตร 2 0.073\n",
      "พรุ่ง 2 0.073\n",
      "สองเอสสาม 2 0.073\n",
      "คะกราฟ 2 0.073\n",
      "เออก 2 0.073\n",
      "ลบอ่ะ 2 0.073\n",
      "สุดเนี่ย 2 0.073\n",
      "เคูณ 2 0.073\n",
      "เอฟเอ็ม 2 0.073\n",
      "duffie 2 0.073\n",
      "fate 2 0.073\n",
      "แอปโซลูทเอ 2 0.073\n",
      "อ่ะเนาะ 2 0.073\n",
      "ซีนซีน 2 0.073\n",
      "ชิปปิ้ง 2 0.073\n",
      "ดับเบิลยู 2 0.073\n",
      "เอ็กซ์อี 2 0.073\n",
      "เอ็นตัว 2 0.073\n",
      "แปรเอ็น 2 0.073\n",
      "เซลโอเมก้า 2 0.073\n",
      "ดำเนิน 2 0.073\n",
      "ดูแล 2 0.073\n",
      "ปุ๊บมัน 2 0.073\n",
      "อาร์เค 2 0.073\n",
      "เดิมเอ็กซ์ 2 0.073\n",
      "ซีบิล 2 0.073\n",
      "ปัญญา 2 0.073\n",
      "มีเอ็น 2 0.073\n",
      "เป็นพริก 2 0.073\n",
      "เอฟเค 2 0.073\n",
      "เอ็กซ์เอ 2 0.073\n",
      "คำนึง 2 0.073\n",
      "เม้นท์ 2 0.073\n",
      "อินเวิร์ด 2 0.073\n",
      "เคเอ็น 2 0.073\n",
      "เค้ก 2 0.073\n",
      "เมทริกซ์ 2 0.073\n",
      "เอสเค 2 0.073\n",
      "ยากจัง 2 0.073\n",
      "hand 2 0.073\n",
      "เยอะหน่อย 2 0.073\n",
      "anser 2 0.073\n",
      "oily 2 0.073\n",
      "จุดประสงค์ 2 0.073\n",
      "ทัวร์ 2 0.073\n",
      "เจ็ดเจ็ด 2 0.073\n",
      "เอสอี 2 0.073\n",
      "แบนดิต 2 0.073\n",
      "decent 2 0.073\n",
      "fical 2 0.073\n",
      "ผ่อน 2 0.073\n",
      "corporate 2 0.073\n",
      "ธันวา 2 0.073\n",
      "บันทึก 2 0.073\n",
      "หัวห้า 2 0.073\n",
      "ออกหัว 2 0.073\n",
      "coming 2 0.073\n",
      "เรียนเรียน 2 0.073\n",
      "dismen 2 0.073\n",
      "เรชั่น 2 0.073\n",
      "เฮีย 2 0.073\n",
      "wine 2 0.073\n",
      "จุ๊บจุ๊บจุ๊บ 2 0.073\n",
      "นิยาย 2 0.073\n",
      "พีเอฟ 2 0.073\n",
      "secant 2 0.073\n",
      "alien 2 0.073\n",
      "curation 2 0.073\n",
      "valentine 2 0.073\n",
      "ตรงไปตรง 2 0.073\n",
      "อีเอ็ม 2 0.073\n",
      "เวเลียน 2 0.073\n",
      "ยินดี 2 0.073\n",
      "สุดสุด 2 0.073\n",
      "หย่า 2 0.073\n",
      "กระชาก 2 0.073\n",
      "กาชา 2 0.073\n",
      "คอยคอย 2 0.073\n",
      "พรรค 2 0.073\n",
      "exponetial 2 0.073\n",
      "เซียนเซียน 2 0.073\n",
      "allen 2 0.073\n",
      "marie 2 0.073\n",
      "meter 2 0.073\n",
      "ขวัญ 2 0.073\n",
      "รุนแรง 2 0.073\n",
      "สแควร์ 2 0.073\n",
      "elon 2 0.073\n",
      "loras 2 0.073\n",
      "standardization 2 0.073\n",
      "แท่งแท่ง 2 0.073\n",
      "there 2 0.073\n",
      "ดิสนีย์ 2 0.073\n",
      "หารเอ็น 2 0.073\n",
      "เล็กเล็กน้อยน้อย 2 0.073\n",
      "โอ้ว้าว 2 0.073\n",
      "ทีโอที 2 0.073\n",
      "oration 2 0.073\n",
      "หล่น 2 0.073\n",
      "binomial 2 0.073\n",
      "ดอกเบี้ย 2 0.073\n",
      "pencil 2 0.073\n",
      "worst 2 0.073\n",
      "เอสแควร์ 2 0.073\n",
      "แบร์เลียน 2 0.073\n",
      "common 2 0.073\n",
      "expedition 2 0.073\n",
      "มันเวิร์ค 2 0.073\n",
      "สุ่มวัน 2 0.073\n",
      "อ่อแล้ว 2 0.073\n",
      "เบเซียน 2 0.073\n",
      "hoppity 2 0.073\n",
      "revision 2 0.073\n",
      "มาเอ็กซ์ 2 0.073\n",
      "เตต้า 2 0.073\n",
      "increasing 2 0.073\n",
      "toray 2 0.073\n",
      "balance 2 0.073\n",
      "male 2 0.073\n",
      "mate 2 0.073\n",
      "warin 2 0.073\n",
      "xtern 2 0.073\n",
      "main 2 0.073\n",
      "paramiter 2 0.073\n",
      "proverty 2 0.073\n",
      "sense 2 0.073\n",
      "indipendent 2 0.073\n",
      "นิดนิดหน่อย 2 0.073\n",
      "บรรทุก 2 0.073\n",
      "อ่ะเดี๋ยว 2 0.073\n",
      "tool 2 0.073\n",
      "เดเบียน 2 0.073\n",
      "นายกอนายก 2 0.073\n",
      "being 2 0.073\n",
      "kemen 2 0.073\n",
      "overy 2 0.073\n",
      "party 2 0.073\n",
      "กรรม 2 0.073\n",
      "จู่จู่ 2 0.073\n",
      "ainol 2 0.073\n",
      "were 2 0.073\n",
      "จ้อง 2 0.073\n",
      "สุนัข 2 0.073\n",
      "กันข้าม 2 0.073\n",
      "อีเม้นท์ 2 0.073\n",
      "แปดเจ็ด 2 0.073\n",
      "diffent 2 0.073\n",
      "จุฬารวย 2 0.073\n",
      "crop 2 0.073\n",
      "exelon 2 0.073\n",
      "ทวีป 2 0.073\n",
      "เปลี่ยนใจ 2 0.073\n",
      "เวิร์ 2 0.073\n",
      "address 2 0.073\n",
      "ออกเดต 2 0.073\n",
      "เรเวล 2 0.073\n",
      "นอร์ม 2 0.073\n",
      "เสี้ยน 2 0.073\n",
      "แอปเปิล 2 0.073\n",
      "anova 2 0.073\n",
      "cation 2 0.073\n",
      "share 2 0.073\n",
      "protesting 2 0.073\n",
      "เว้ย 2 0.073\n",
      "enery 2 0.073\n",
      "leading 2 0.073\n",
      "สงคราม 2 0.073\n",
      "colection 2 0.073\n",
      "convetion 2 0.073\n",
      "แหวน 2 0.073\n",
      "พิเคชั่น 2 0.073\n",
      "ร้อยร้อย 2 0.073\n",
      "เอพีเอส 2 0.073\n",
      "bitec 2 0.073\n",
      "ข้อความ 2 0.073\n",
      "วัดยาก 2 0.073\n",
      "digital 2 0.073\n",
      "รัฐบาล 2 0.073\n",
      "เป็นเหตุ 2 0.073\n",
      "marketing 2 0.073\n",
      "พฤติกรรม 2 0.073\n",
      "confounder 2 0.073\n",
      "controller 2 0.073\n",
      "group 2 0.073\n",
      "ipad 2 0.073\n",
      "amazon 2 0.073\n",
      "landon 2 0.073\n",
      "poses 2 0.073\n",
      "randomness 2 0.073\n",
      "เคี้ยว 2 0.073\n",
      "animation 2 0.073\n",
      "listing 2 0.073\n",
      "visit 2 0.073\n",
      "fasion 2 0.073\n",
      "track 2 0.073\n",
      "ล็อคอิน 2 0.073\n",
      "เลขเลข 2 0.073\n",
      "ตู้ม 2 0.073\n",
      "วัดวัด 2 0.073\n",
      "มิเรียม 2 0.073\n",
      "conservative 2 0.073\n",
      "ยูเซอร์ 2 0.073\n",
      "เกรท 2 0.073\n",
      "เข้าเพจ 2 0.073\n",
      "กราฟกราฟ 2 0.073\n",
      "decant 2 0.073\n",
      "late 2 0.073\n",
      "คุณคุณ 2 0.073\n",
      "ชิหาย 2 0.073\n",
      "ชัยชนะ 2 0.073\n",
      "คุณคำนวณ 2 0.073\n",
      "ชัวร์ชัวร์ 2 0.073\n",
      "ดิวิชั่น 2 0.073\n",
      "เอ็มดี 2 0.073\n",
      "ล่องลอย 2 0.073\n",
      "สัมชัน 2 0.073\n",
      "เมทริก 2 0.073\n",
      "เก็บเก็บ 2 0.073\n",
      "เสียห้า 2 0.073\n",
      "เสียบ 2 0.073\n",
      "ซีซั่น 2 0.073\n",
      "apassing 2 0.073\n",
      "โยกโยก 2 0.073\n",
      "xplore 2 0.073\n"
     ]
    }
   ],
   "source": [
    "for idx,freq in sort_freq:\n",
    "  print(dictionary[idx],freq,round((freq)*100/len(dictionary),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "add_stop_word = []\n",
    "thresh = 11\n",
    "for idx,freq in sort_freq:\n",
    "  percent = round((freq)*100/len(dictionary),2)\n",
    "  if (percent < thresh) : break\n",
    "  add_stop_word.append(idx)\n",
    "\n",
    "print(len(add_stop_word))\n",
    "# delete stop word\n",
    "for sentence in bow_corpus:\n",
    "  idx = []\n",
    "  for i in range(len(sentence)):\n",
    "    if (sentence[i][0] in add_stop_word):\n",
    "      idx.append(i)\n",
    "\n",
    "  idx.sort(reverse=True)\n",
    "  for j in range(len(idx)):\n",
    "    sentence.pop(idx[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "Word 3 (\"data\") appears 1 time.\n",
      "Word 5 (\"force\") appears 1 time.\n",
      "Word 8 (\"optimization\") appears 7 time.\n",
      "Word 16 (\"กระบวนการ\") appears 1 time.\n",
      "Word 21 (\"จำนวน\") appears 3 time.\n",
      "Word 22 (\"จินตนาการ\") appears 1 time.\n",
      "Word 23 (\"ต่างต่าง\") appears 1 time.\n",
      "Word 27 (\"นั่ง\") appears 1 time.\n",
      "Word 37 (\"วิชา\") appears 2 time.\n",
      "Word 42 (\"สมมติ\") appears 2 time.\n",
      "Word 51 (\"หมาย\") appears 2 time.\n",
      "Word 60 (\"อ่าน\") appears 5 time.\n",
      "Word 68 (\"เปอร์เซ็นต์\") appears 1 time.\n",
      "Word 77 (\"เสียง\") appears 2 time.\n",
      "Word 78 (\"เอ่อ\") appears 1 time.\n",
      "Word 89 (\"active\") appears 1 time.\n",
      "Word 90 (\"ative\") appears 1 time.\n",
      "Word 91 (\"center\") appears 1 time.\n",
      "Word 92 (\"core\") appears 1 time.\n",
      "Word 93 (\"decision\") appears 2 time.\n",
      "Word 94 (\"dicision\") appears 1 time.\n",
      "Word 95 (\"dison\") appears 1 time.\n",
      "Word 96 (\"facebook\") appears 1 time.\n",
      "Word 97 (\"feature\") appears 4 time.\n",
      "Word 98 (\"from\") appears 1 time.\n",
      "Word 99 (\"learning\") appears 2 time.\n",
      "Word 100 (\"location\") appears 1 time.\n",
      "Word 101 (\"machine\") appears 1 time.\n",
      "Word 102 (\"maximize\") appears 2 time.\n",
      "Word 103 (\"minimize\") appears 1 time.\n",
      "Word 104 (\"model\") appears 1 time.\n",
      "Word 105 (\"optimize\") appears 1 time.\n",
      "Word 106 (\"resource\") appears 2 time.\n",
      "Word 107 (\"smart\") appears 2 time.\n",
      "Word 108 (\"tata\") appears 1 time.\n",
      "Word 109 (\"tive\") appears 1 time.\n",
      "Word 110 (\"varible\") appears 1 time.\n",
      "Word 111 (\"กรรมการ\") appears 1 time.\n",
      "Word 112 (\"ความหมาย\") appears 1 time.\n",
      "Word 113 (\"คอนเทน\") appears 1 time.\n",
      "Word 114 (\"คอมพิวเตอร์\") appears 1 time.\n",
      "Word 115 (\"คำนวณ\") appears 1 time.\n",
      "Word 116 (\"งั้น\") appears 1 time.\n",
      "Word 117 (\"ง่ายง่าย\") appears 2 time.\n",
      "Word 118 (\"จำกัด\") appears 3 time.\n",
      "Word 119 (\"ชื่อ\") appears 1 time.\n",
      "Word 120 (\"ซิทีฟ\") appears 1 time.\n",
      "Word 121 (\"ซึ้ง\") appears 1 time.\n",
      "Word 122 (\"ดีดี\") appears 1 time.\n",
      "Word 123 (\"ตรงไปตรงมา\") appears 1 time.\n",
      "Word 124 (\"ตัดสินใจ\") appears 3 time.\n",
      "Word 125 (\"ตัวอย่าง\") appears 3 time.\n",
      "Word 126 (\"ตั้ม\") appears 1 time.\n",
      "Word 127 (\"ต้องการ\") appears 1 time.\n",
      "Word 128 (\"ทีวี\") appears 1 time.\n",
      "Word 129 (\"นาที\") appears 1 time.\n",
      "Word 130 (\"ประโยชน์\") appears 2 time.\n",
      "Word 131 (\"ผลิต\") appears 2 time.\n",
      "Word 132 (\"พัฒนา\") appears 2 time.\n",
      "Word 133 (\"ภาษา\") appears 1 time.\n",
      "Word 134 (\"มุมมอง\") appears 1 time.\n",
      "Word 135 (\"รวยรวย\") appears 1 time.\n",
      "Word 136 (\"ราคา\") appears 1 time.\n",
      "Word 137 (\"ลักษณะ\") appears 1 time.\n",
      "Word 138 (\"วิธี\") appears 1 time.\n",
      "Word 139 (\"สมการ\") appears 1 time.\n",
      "Word 140 (\"สมมุติ\") appears 2 time.\n",
      "Word 141 (\"สาขา\") appears 3 time.\n",
      "Word 142 (\"สิทธิ์\") appears 1 time.\n",
      "Word 143 (\"หลักหลัก\") appears 3 time.\n",
      "Word 144 (\"หวัง\") appears 1 time.\n",
      "Word 145 (\"ห่าง\") appears 1 time.\n",
      "Word 146 (\"ออกซิทีฟ\") appears 1 time.\n",
      "Word 147 (\"อิสาน\") appears 1 time.\n",
      "Word 148 (\"เก้า\") appears 1 time.\n",
      "Word 149 (\"เงิน\") appears 1 time.\n",
      "Word 150 (\"เนื้อหา\") appears 1 time.\n",
      "Word 151 (\"เปล่า\") appears 1 time.\n",
      "Word 152 (\"เป้าหมาย\") appears 2 time.\n",
      "Word 153 (\"เรียนรู้\") appears 1 time.\n",
      "Word 154 (\"เอ่ย\") appears 1 time.\n",
      "Word 155 (\"แคลคูลัส\") appears 1 time.\n",
      "Word 156 (\"แบ่ง\") appears 1 time.\n",
      "Word 157 (\"แปรหลัก\") appears 1 time.\n",
      "Word 158 (\"โค้ด\") appears 1 time.\n",
      "Word 159 (\"โจทก์\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_01 = bow_corpus[1]\n",
    "print(len(bow_doc_01))\n",
    "for i in range(len(bow_doc_01)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_01[i][0],\n",
    "                                               dictionary[bow_doc_01[i][0]], bow_doc_01[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26:02:45:47 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:46:03 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:46:18 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:46:34 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:46:49 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:47:05 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:47:21 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:47:37 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:47:53 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:48:09 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:48:25 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:48:40 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:48:56 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:49:12 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-02-26:02:49:28 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics: 39\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define range of candidate numbers of topics\n",
    "num_topics_range = range(35, 42)\n",
    "# TOPIC = 28\n",
    "gensim_seed = 11\n",
    "# Calculate coherence scores\n",
    "coherence_scores = []\n",
    "for num_topics in num_topics_range:\n",
    "    lda_model = LdaMulticore(bow_corpus, num_topics=num_topics, \\\n",
    "                                       id2word=dictionary, passes=2, workers=2, \\\n",
    "                                       random_state=gensim_seed)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=df['token_ls'], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "\n",
    "# Plot coherence scores\n",
    "plt.plot(num_topics_range, coherence_scores)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"Coherence Score vs. Number of Topics\")\n",
    "plt.xticks(num_topics_range)\n",
    "plt.show()\n",
    "\n",
    "# Find optimal number of topics\n",
    "optimal_num_topics = num_topics_range[np.argmax(coherence_scores)]\n",
    "print(\"Optimal number of topics:\", optimal_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26:05:15:22 WARNING  [gensim.models.ldamulticore:253] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.021*\"ซื้อ\" + 0.013*\"transform\" + 0.012*\"ลูกค้า\" + 0.012*\"เอ่อ\" + 0.011*\"ร้อย\" + 0.011*\"เอ็ด\" + 0.011*\"วิธี\" + 0.011*\"เดือน\" + 0.011*\"เจเค\" + 0.009*\"สมมุติ\"\n",
      "Topic: 1 \n",
      "Words: 0.020*\"เก้า\" + 0.017*\"ข้อมูล\" + 0.011*\"คำนวณ\" + 0.010*\"สุดท้าย\" + 0.010*\"customer\" + 0.010*\"เปอร์เซ็นต์\" + 0.010*\"เพื่อน\" + 0.009*\"ร้อย\" + 0.009*\"ล็อค\" + 0.009*\"เอ่อ\"\n",
      "Topic: 2 \n",
      "Words: 0.021*\"ข้อมูล\" + 0.013*\"อ่าน\" + 0.012*\"นะนะ\" + 0.012*\"สมมุติ\" + 0.012*\"เอ่อ\" + 0.010*\"คะแนน\" + 0.009*\"เหลี่ยม\" + 0.009*\"ตัวอย่าง\" + 0.009*\"สัญญา\" + 0.009*\"อธิบาย\"\n",
      "Topic: 3 \n",
      "Words: 0.027*\"power\" + 0.017*\"ข้อมูล\" + 0.013*\"เอ่อ\" + 0.012*\"ตัวอย่าง\" + 0.012*\"หมาย\" + 0.012*\"คำนวณ\" + 0.011*\"เหรียญ\" + 0.009*\"ปกติ\" + 0.009*\"data\" + 0.009*\"สนใจ\"\n",
      "Topic: 4 \n",
      "Words: 0.031*\"integrate\" + 0.022*\"เล่น\" + 0.018*\"ซ้ำกัน\" + 0.016*\"เลื่อน\" + 0.015*\"เส้น\" + 0.013*\"คีย์\" + 0.013*\"งั้น\" + 0.013*\"เหลี่ยม\" + 0.013*\"เช็ค\" + 0.012*\"ทาว์\"\n",
      "Topic: 5 \n",
      "Words: 0.018*\"จำนวน\" + 0.014*\"ซื้อ\" + 0.011*\"ลูกค้า\" + 0.011*\"เก้า\" + 0.010*\"สมมุติ\" + 0.010*\"หลักหลัก\" + 0.008*\"ข้อมูล\" + 0.008*\"สุดท้าย\" + 0.008*\"เลือก\" + 0.008*\"convolution\"\n",
      "Topic: 6 \n",
      "Words: 0.018*\"ซื้อ\" + 0.015*\"จำนวน\" + 0.013*\"ล่าง\" + 0.012*\"อาร์\" + 0.012*\"สมการ\" + 0.011*\"หมาย\" + 0.011*\"เอ่อ\" + 0.009*\"ทดลอง\" + 0.009*\"พิจารณา\" + 0.009*\"อ่าน\"\n",
      "Topic: 7 \n",
      "Words: 0.016*\"นาที\" + 0.013*\"บ้าน\" + 0.013*\"เฉลี่ย\" + 0.011*\"เอ่อ\" + 0.011*\"อ่าน\" + 0.009*\"สนใจ\" + 0.009*\"มุมมอง\" + 0.009*\"เลื่อน\" + 0.009*\"สุดท้าย\" + 0.008*\"ร้อย\"\n",
      "Topic: 8 \n",
      "Words: 0.031*\"เปอร์เซ็นต์\" + 0.030*\"รางวัล\" + 0.025*\"เก้า\" + 0.020*\"เอ่อ\" + 0.020*\"reward\" + 0.020*\"โอกาส\" + 0.017*\"ซื้อ\" + 0.015*\"ลอตเตอรี่\" + 0.015*\"เงิน\" + 0.012*\"setting\"\n",
      "Topic: 9 \n",
      "Words: 0.025*\"เดลต้า\" + 0.016*\"เพื่อน\" + 0.013*\"ระบบ\" + 0.011*\"เลื่อน\" + 0.010*\"เรื่อยเรื่อย\" + 0.010*\"นาที\" + 0.010*\"รูปแบบ\" + 0.010*\"เล่น\" + 0.009*\"ฟังก์ชัน\" + 0.008*\"เหลี่ยม\"\n",
      "Topic: 10 \n",
      "Words: 0.034*\"เปอร์เซ็นต์\" + 0.023*\"คะแนน\" + 0.016*\"เอ็ม\" + 0.016*\"หมาย\" + 0.015*\"อียก\" + 0.012*\"เจเค\" + 0.011*\"เนาะนะ\" + 0.011*\"อ่าน\" + 0.011*\"เอ็ด\" + 0.010*\"กระบวนการ\"\n",
      "Topic: 11 \n",
      "Words: 0.021*\"รูปแบบ\" + 0.019*\"สมการ\" + 0.019*\"เลือก\" + 0.015*\"ระบบ\" + 0.013*\"input\" + 0.012*\"กลาย\" + 0.010*\"ซื้อ\" + 0.009*\"วิธี\" + 0.009*\"อ่าน\" + 0.008*\"เปล่า\"\n",
      "Topic: 12 \n",
      "Words: 0.070*\"เอ็ม\" + 0.019*\"แปลง\" + 0.016*\"วิธี\" + 0.016*\"เอ็กซ์เอ็น\" + 0.015*\"เดลต้า\" + 0.015*\"เสียง\" + 0.013*\"เนาะนะ\" + 0.012*\"ตัวอย่าง\" + 0.012*\"ล่าง\" + 0.012*\"รูปแบบ\"\n",
      "Topic: 13 \n",
      "Words: 0.036*\"สมการ\" + 0.028*\"เส้น\" + 0.026*\"เดลต้า\" + 0.021*\"วิธี\" + 0.018*\"เอ่อ\" + 0.018*\"แปลง\" + 0.018*\"solution\" + 0.017*\"point\" + 0.016*\"extreme\" + 0.012*\"เลือก\"\n",
      "Topic: 14 \n",
      "Words: 0.017*\"เลือก\" + 0.016*\"ศุกร์\" + 0.016*\"บ้าน\" + 0.015*\"เดี๋ยวเดี๋ยว\" + 0.012*\"วิชา\" + 0.012*\"ออนไลน์\" + 0.011*\"user\" + 0.011*\"เส้น\" + 0.010*\"เพื่อน\" + 0.010*\"เปอร์เซ็นต์\"\n",
      "Topic: 15 \n",
      "Words: 0.024*\"เก้า\" + 0.021*\"พัดลม\" + 0.016*\"วัคซีน\" + 0.016*\"เอ็ด\" + 0.015*\"ตัวอย่าง\" + 0.014*\"ทดลอง\" + 0.014*\"ปิ้ง\" + 0.010*\"เตรียม\" + 0.010*\"ยูที\" + 0.010*\"เปอร์เซ็นต์\"\n",
      "Topic: 16 \n",
      "Words: 0.022*\"จุดห้า\" + 0.021*\"ข้อมูล\" + 0.020*\"เหรียญ\" + 0.017*\"เล่น\" + 0.014*\"data\" + 0.011*\"สมการ\" + 0.010*\"สำหรับ\" + 0.010*\"คะแนน\" + 0.010*\"มุมมอง\" + 0.010*\"สมมุติ\"\n",
      "Topic: 17 \n",
      "Words: 0.021*\"อียก\" + 0.015*\"integrate\" + 0.011*\"สมมุติ\" + 0.009*\"เทียบ\" + 0.009*\"เรียว\" + 0.009*\"เดลต้า\" + 0.008*\"เหลี่ยม\" + 0.008*\"คำนวณ\" + 0.008*\"เก้า\" + 0.007*\"เอลบ\"\n",
      "Topic: 18 \n",
      "Words: 0.022*\"ตำแหน่ง\" + 0.022*\"เดลต้า\" + 0.017*\"โปรแกรม\" + 0.015*\"ขยาย\" + 0.014*\"ฟังก์ชัน\" + 0.012*\"สเกล\" + 0.011*\"ยูเอ็น\" + 0.011*\"ย้าย\" + 0.009*\"เปล่า\" + 0.009*\"ซ้าย\"\n",
      "Topic: 19 \n",
      "Words: 0.021*\"เช็ค\" + 0.014*\"ข้อมูล\" + 0.013*\"เฉลี่ย\" + 0.011*\"ชื่อ\" + 0.011*\"เก้า\" + 0.011*\"บ้าน\" + 0.010*\"ขนาด\" + 0.010*\"วิธี\" + 0.010*\"value\" + 0.008*\"ตัวอย่าง\"\n",
      "Topic: 20 \n",
      "Words: 0.026*\"เหรียญ\" + 0.023*\"โอกาส\" + 0.022*\"เปอร์เซ็นต์\" + 0.020*\"ข้อมูล\" + 0.016*\"เลือก\" + 0.013*\"วิธี\" + 0.011*\"ตัวอย่าง\" + 0.010*\"เอ่อ\" + 0.010*\"หมาย\" + 0.010*\"เรื่อยเรื่อย\"\n",
      "Topic: 21 \n",
      "Words: 0.026*\"รูปแบบ\" + 0.022*\"ระบบ\" + 0.016*\"เอ็ม\" + 0.013*\"เอเอ็กซ์\" + 0.013*\"อียก\" + 0.010*\"แปลง\" + 0.010*\"input\" + 0.009*\"ตัวอย่าง\" + 0.009*\"convolution\" + 0.009*\"กระจาย\"\n",
      "Topic: 22 \n",
      "Words: 0.024*\"ฮาร์มอนิก\" + 0.017*\"สมการ\" + 0.016*\"ฮาร์โมนิค\" + 0.016*\"เลือก\" + 0.015*\"หลัก\" + 0.014*\"พรีเซนต์\" + 0.012*\"ปุ๊บ\" + 0.012*\"ตัวอย่าง\" + 0.011*\"อ่าน\" + 0.010*\"รูปแบบ\"\n",
      "Topic: 23 \n",
      "Words: 0.016*\"เดลต้า\" + 0.016*\"อินฟินิตี้\" + 0.015*\"รูปแบบ\" + 0.014*\"พิจารณา\" + 0.012*\"convolution\" + 0.010*\"เหลี่ยม\" + 0.010*\"เอ็กซ์เอ็น\" + 0.010*\"นะนะ\" + 0.009*\"ฟังก์ชัน\" + 0.009*\"แปลง\"\n",
      "Topic: 24 \n",
      "Words: 0.025*\"ระบบ\" + 0.016*\"input\" + 0.016*\"เสียง\" + 0.014*\"convolution\" + 0.013*\"ตัวอย่าง\" + 0.012*\"รูปแบบ\" + 0.012*\"พิจารณา\" + 0.011*\"เพลง\" + 0.009*\"สมมุติ\" + 0.009*\"สัญญา\"\n",
      "Topic: 25 \n",
      "Words: 0.024*\"เอ็ม\" + 0.020*\"เงิน\" + 0.020*\"พิจารณา\" + 0.019*\"เลื่อน\" + 0.017*\"รูปแบบ\" + 0.017*\"เดือน\" + 0.016*\"ซ้าย\" + 0.015*\"มหาลัย\" + 0.014*\"สุดท้าย\" + 0.013*\"สเกล\"\n",
      "Topic: 26 \n",
      "Words: 0.019*\"เจ็ด\" + 0.017*\"ข้อมูล\" + 0.016*\"ไซน์\" + 0.016*\"เฉลี่ย\" + 0.015*\"เซต้า\" + 0.013*\"วิธี\" + 0.011*\"ล่าง\" + 0.010*\"integrate\" + 0.009*\"normal\" + 0.008*\"ซิงค์\"\n",
      "Topic: 27 \n",
      "Words: 0.085*\"เดลต้า\" + 0.050*\"ฟังก์ชัน\" + 0.030*\"integrate\" + 0.023*\"คำนวณ\" + 0.016*\"สมบัติ\" + 0.016*\"ฟังก์ชั่น\" + 0.015*\"กระจาย\" + 0.014*\"ขยาย\" + 0.014*\"สุดท้าย\" + 0.013*\"ขนาด\"\n",
      "Topic: 28 \n",
      "Words: 0.015*\"คลื่น\" + 0.013*\"ข้อมูล\" + 0.011*\"เลือก\" + 0.010*\"หมาย\" + 0.010*\"เครื่อง\" + 0.010*\"สมมุติ\" + 0.009*\"เพื่อน\" + 0.009*\"เอ่อ\" + 0.009*\"สำหรับ\" + 0.009*\"อ่าน\"\n",
      "Topic: 29 \n",
      "Words: 0.035*\"ระบบ\" + 0.028*\"รูปแบบ\" + 0.024*\"output\" + 0.020*\"input\" + 0.020*\"integrate\" + 0.013*\"ฟังก์ชัน\" + 0.012*\"เงิน\" + 0.012*\"ตัวอย่าง\" + 0.011*\"เดลต้า\" + 0.011*\"เดือน\"\n",
      "Topic: 30 \n",
      "Words: 0.017*\"บ้าน\" + 0.013*\"จำนวน\" + 0.012*\"โอกาส\" + 0.011*\"สมมุติ\" + 0.011*\"เลือก\" + 0.011*\"หมาย\" + 0.010*\"เอ่อ\" + 0.010*\"คำนวณ\" + 0.010*\"เล่น\" + 0.009*\"อ่าน\"\n",
      "Topic: 31 \n",
      "Words: 0.039*\"ร้อย\" + 0.019*\"ทดลอง\" + 0.017*\"เก้า\" + 0.015*\"เปอร์เซ็นต์\" + 0.015*\"อ่าน\" + 0.012*\"มุมมอง\" + 0.011*\"ตัวอย่าง\" + 0.011*\"เลือก\" + 0.010*\"โอกาส\" + 0.010*\"เปล่า\"\n",
      "Topic: 32 \n",
      "Words: 0.021*\"เครื่อง\" + 0.019*\"ร้าน\" + 0.015*\"เอ็ด\" + 0.014*\"ชื่อ\" + 0.012*\"หยิบ\" + 0.012*\"ข้อมูล\" + 0.012*\"เก้า\" + 0.011*\"ระวัง\" + 0.010*\"เอ่อ\" + 0.010*\"สองสามสี่ห้า\"\n",
      "Topic: 33 \n",
      "Words: 0.034*\"ซิกนัม\" + 0.022*\"ยูที\" + 0.019*\"integrate\" + 0.017*\"พิจารณา\" + 0.015*\"transform\" + 0.015*\"furia\" + 0.013*\"จันทร์\" + 0.013*\"รูปแบบ\" + 0.012*\"ซ้าย\" + 0.011*\"ครู่\"\n",
      "Topic: 34 \n",
      "Words: 0.021*\"วิชา\" + 0.016*\"เลือก\" + 0.012*\"เสียง\" + 0.009*\"สนใจ\" + 0.009*\"โอกาส\" + 0.009*\"เช็ค\" + 0.008*\"อ่าน\" + 0.008*\"วิธี\" + 0.008*\"สำหรับ\" + 0.008*\"เล่น\"\n",
      "Topic: 35 \n",
      "Words: 0.023*\"สุดท้าย\" + 0.017*\"เส้น\" + 0.014*\"เบต้า\" + 0.013*\"สนใจ\" + 0.013*\"ซื้อ\" + 0.013*\"ขยับ\" + 0.012*\"อ่าน\" + 0.012*\"เจ็ด\" + 0.011*\"สมการ\" + 0.010*\"บ้าน\"\n",
      "Topic: 36 \n",
      "Words: 0.016*\"optimization\" + 0.014*\"อ่าน\" + 0.013*\"input\" + 0.013*\"เติม\" + 0.012*\"เสียง\" + 0.012*\"วิธี\" + 0.009*\"หลักหลัก\" + 0.008*\"เทอม\" + 0.008*\"เล่ม\" + 0.008*\"ปุ๊บ\"\n",
      "Topic: 37 \n",
      "Words: 0.019*\"ซิงค์\" + 0.015*\"นะนะ\" + 0.014*\"อียก\" + 0.014*\"furia\" + 0.014*\"คำนวณ\" + 0.013*\"เหลี่ยม\" + 0.013*\"convolution\" + 0.012*\"เอ็ม\" + 0.010*\"สมมุติ\" + 0.010*\"เจ็ด\"\n",
      "Topic: 38 \n",
      "Words: 0.030*\"เก้า\" + 0.012*\"เจ็ด\" + 0.011*\"โดเมน\" + 0.010*\"สัญญา\" + 0.010*\"freeny\" + 0.010*\"ทิ้ง\" + 0.010*\"สนใจ\" + 0.009*\"เฮ้ย\" + 0.009*\"เปอร์เซ็นต์\" + 0.008*\"คุณสมบัติ\"\n"
     ]
    }
   ],
   "source": [
    "random_seed = 11\n",
    "gensim_seed = gensim.utils.get_random_state(random_seed)\n",
    "TOPIC = 39\n",
    "num_topic = optimal_num_topics\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=num_topic, \\\n",
    "                                       id2word=dictionary, passes=2, workers=2, \\\n",
    "                                       random_state=gensim_seed)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(35, 0.8376055)]\n",
      "Score: 0.8376054763793945\t Topic: 0.023*\"สุดท้าย\" + 0.017*\"เส้น\" + 0.014*\"เบต้า\" + 0.013*\"สนใจ\" + 0.013*\"ซื้อ\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = ' 0.023*\"สุดท้าย\" + 0.017*\"เส้น\" + 0.014*\"เบต้า\" + 0.013*\"สนใจ\" + 0.013*\"ซื้อ\"'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "print(lda_model[bow_vector])\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from evaluation.evaluate_LDA2 import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(\"../../labeled/labeled_transcript_02.csv\", index_col=0)\n",
    "new_tmp = get_topic_distribution(lda_model, tmp, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(np.stack(tmp.topic_distribution.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.51281625 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.51280499\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092]\n",
      "[0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.51280499\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092 0.01282092\n",
      " 0.01282092 0.01282092 0.01282092]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.67521143 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282399 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399\n",
      " 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399\n",
      " 0.01282399 0.51268828 0.01282399 0.01282399 0.01282399 0.01282399\n",
      " 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399\n",
      " 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399\n",
      " 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399 0.01282399\n",
      " 0.01282399 0.01282399 0.01282399]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5736354  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.18908657\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.67518544\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31583762 0.         0.         0.         0.\n",
      " 0.         0.         0.44694409]\n",
      "[0.01282838 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838\n",
      " 0.01282838 0.51252151 0.01282838 0.01282838 0.01282838 0.01282838\n",
      " 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838\n",
      " 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838\n",
      " 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838\n",
      " 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838 0.01282838\n",
      " 0.01282838 0.01282838 0.01282838]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.50638193 0.         0.         0.         0.25629625 0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282134 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134\n",
      " 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134\n",
      " 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134\n",
      " 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134\n",
      " 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134\n",
      " 0.01282134 0.01282134 0.01282134 0.01282134 0.01282134 0.51278889\n",
      " 0.01282134 0.01282134 0.01282134]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.67519939 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.87817228 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.80511403 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.51281637 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.67519915 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.8050974 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.       ]\n",
      "[0.01282085 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085\n",
      " 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085\n",
      " 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085\n",
      " 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085\n",
      " 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085 0.01282085\n",
      " 0.01282085 0.01282085 0.51280773 0.01282085 0.01282085 0.01282085\n",
      " 0.01282085 0.01282085 0.01282085]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.80509889 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282078 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078\n",
      " 0.01282078 0.01282078 0.51281041 0.01282078 0.01282078 0.01282078\n",
      " 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078\n",
      " 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078\n",
      " 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078\n",
      " 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078 0.01282078\n",
      " 0.01282078 0.01282078 0.01282078]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.87819648 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.80510491 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.67520571 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.86080033 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.75638568 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.75639385 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.38172296 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.42851248]\n",
      "[0.01282455 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455\n",
      " 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455\n",
      " 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455\n",
      " 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455\n",
      " 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455\n",
      " 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455 0.01282455\n",
      " 0.01282455 0.01282455 0.51266718]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20515364 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.40509373 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20500262 0.\n",
      " 0.         0.         0.        ]\n",
      "[0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.8917281 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.       ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.67516285 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.26372254 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49906236 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.80508971 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.67520547 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282387 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387\n",
      " 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387\n",
      " 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387\n",
      " 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387\n",
      " 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387 0.01282387\n",
      " 0.01282387 0.01282387 0.01282387 0.01282387 0.51269287 0.01282387\n",
      " 0.01282387 0.01282387 0.01282387]\n",
      "[0.         0.67519993 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282271 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271\n",
      " 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271\n",
      " 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271\n",
      " 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271\n",
      " 0.01282271 0.01282271 0.51273692 0.01282271 0.01282271 0.01282271\n",
      " 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271 0.01282271\n",
      " 0.01282271 0.01282271 0.01282271]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.67519987 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.42137045 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34142002 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.0128282  0.0128282  0.0128282  0.0128282  0.0128282  0.0128282\n",
      " 0.0128282  0.0128282  0.0128282  0.0128282  0.0128282  0.0128282\n",
      " 0.0128282  0.0128282  0.0128282  0.0128282  0.0128282  0.0128282\n",
      " 0.0128282  0.0128282  0.51252854 0.0128282  0.0128282  0.0128282\n",
      " 0.0128282  0.0128282  0.0128282  0.0128282  0.0128282  0.0128282\n",
      " 0.0128282  0.0128282  0.0128282  0.0128282  0.0128282  0.0128282\n",
      " 0.0128282  0.0128282  0.0128282 ]\n",
      "[0.01282439 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439\n",
      " 0.01282439 0.51267314 0.01282439 0.01282439 0.01282439 0.01282439\n",
      " 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439\n",
      " 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439\n",
      " 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439\n",
      " 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439 0.01282439\n",
      " 0.01282439 0.01282439 0.01282439]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.75636393 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.83757019 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282087 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087\n",
      " 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087\n",
      " 0.01282087 0.01282087 0.01282087 0.01282087 0.51280689 0.01282087\n",
      " 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087\n",
      " 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087\n",
      " 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087 0.01282087\n",
      " 0.01282087 0.01282087 0.01282087]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.33189583 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.35175595 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28520736 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.52498811 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.83759677 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.67514998 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.75637126 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.24496426 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.61948305 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.63146079 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1787807  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.90255409 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.67515373 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.83758599 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.80511022 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282153 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153\n",
      " 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153\n",
      " 0.01282153 0.01282153 0.01282153 0.01282153 0.51278174 0.01282153\n",
      " 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153\n",
      " 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153\n",
      " 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153 0.01282153\n",
      " 0.01282153 0.01282153 0.01282153]\n",
      "[0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.7563895 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.       ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.80508977 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.3218815  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.36178669 0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282058 0.01282058 0.01282058 0.01282058 0.51281798 0.01282058\n",
      " 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058\n",
      " 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058\n",
      " 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058\n",
      " 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058\n",
      " 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058 0.01282058\n",
      " 0.01282058 0.01282058 0.01282058]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.83757716 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.75635403 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34942704 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.33430824 0.        ]\n",
      "[0.         0.75638908 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.75639969 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.67516786 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.2036134  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.55914938 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.75618184 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.51281625 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062 0.01282062\n",
      " 0.01282062 0.01282062 0.01282062]\n",
      "[0.01282432 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432\n",
      " 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432\n",
      " 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432\n",
      " 0.01282432 0.01282432 0.51267594 0.01282432 0.01282432 0.01282432\n",
      " 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432\n",
      " 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432 0.01282432\n",
      " 0.01282432 0.01282432 0.01282432]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.80512071 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.29736057 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.46543661 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17101823 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23146892 0.         0.46560252 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.0128212  0.0128212  0.0128212  0.0128212  0.0128212  0.0128212\n",
      " 0.0128212  0.0128212  0.0128212  0.0128212  0.0128212  0.0128212\n",
      " 0.0128212  0.0128212  0.0128212  0.0128212  0.0128212  0.0128212\n",
      " 0.0128212  0.0128212  0.0128212  0.0128212  0.0128212  0.0128212\n",
      " 0.0128212  0.0128212  0.0128212  0.0128212  0.51279444 0.0128212\n",
      " 0.0128212  0.0128212  0.0128212  0.0128212  0.0128212  0.0128212\n",
      " 0.0128212  0.0128212  0.0128212 ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.80510581 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282279 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279\n",
      " 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279\n",
      " 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279\n",
      " 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279\n",
      " 0.01282279 0.01282279 0.512734   0.01282279 0.01282279 0.01282279\n",
      " 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279 0.01282279\n",
      " 0.01282279 0.01282279 0.01282279]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.86079383 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.83759433 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.80511349 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.67520779 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282229 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229\n",
      " 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229\n",
      " 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229\n",
      " 0.01282229 0.01282229 0.51275313 0.01282229 0.01282229 0.01282229\n",
      " 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229\n",
      " 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229 0.01282229\n",
      " 0.01282229 0.01282229 0.01282229]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282074 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074\n",
      " 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074\n",
      " 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074\n",
      " 0.01282074 0.01282074 0.01282074 0.01282074 0.51281172 0.01282074\n",
      " 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074\n",
      " 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074 0.01282074\n",
      " 0.01282074 0.01282074 0.01282074]\n",
      "[0.01282434 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434\n",
      " 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434\n",
      " 0.01282434 0.01282434 0.01282434 0.51267511 0.01282434 0.01282434\n",
      " 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434\n",
      " 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434\n",
      " 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434 0.01282434\n",
      " 0.01282434 0.01282434 0.01282434]\n",
      "[0.         0.34183326 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34186283 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.83757991 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.75633991 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.86077738 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.86078376 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.86078858 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.89172024 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282218 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218\n",
      " 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218\n",
      " 0.01282218 0.01282218 0.01282218 0.01282218 0.51275694 0.01282218\n",
      " 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218\n",
      " 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218\n",
      " 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218 0.01282218\n",
      " 0.01282218 0.01282218 0.01282218]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.80507779 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.80508173 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.67515552 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282164 0.01282164 0.01282164 0.01282164 0.51277781 0.01282164\n",
      " 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164\n",
      " 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164\n",
      " 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164\n",
      " 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164\n",
      " 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164 0.01282164\n",
      " 0.01282164 0.01282164 0.01282164]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.75639486 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.83756959 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.75636995 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.0128235  0.0128235  0.0128235  0.0128235  0.0128235  0.0128235\n",
      " 0.0128235  0.0128235  0.0128235  0.0128235  0.0128235  0.0128235\n",
      " 0.0128235  0.0128235  0.0128235  0.0128235  0.0128235  0.0128235\n",
      " 0.0128235  0.0128235  0.0128235  0.0128235  0.0128235  0.0128235\n",
      " 0.0128235  0.0128235  0.0128235  0.0128235  0.0128235  0.0128235\n",
      " 0.0128235  0.0128235  0.0128235  0.0128235  0.51270711 0.0128235\n",
      " 0.0128235  0.0128235  0.0128235 ]\n",
      "[0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.51281494 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066]\n",
      "[0.01282354 0.5127055  0.01282354 0.01282354 0.01282354 0.01282354\n",
      " 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354\n",
      " 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354\n",
      " 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354\n",
      " 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354\n",
      " 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354 0.01282354\n",
      " 0.01282354 0.01282354 0.01282354]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.67515498 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282499 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499\n",
      " 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499\n",
      " 0.01282499 0.01282499 0.01282499 0.01282499 0.51265043 0.01282499\n",
      " 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499\n",
      " 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499\n",
      " 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499 0.01282499\n",
      " 0.01282499 0.01282499 0.01282499]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.67521179 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.50638217 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.25629616 0.\n",
      " 0.         0.         0.        ]\n",
      "[0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.7563802 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.       ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.90255284 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.67519385 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.86079359 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282219 0.01282219 0.01282219 0.51275682 0.01282219 0.01282219\n",
      " 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219\n",
      " 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219\n",
      " 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219\n",
      " 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219\n",
      " 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219 0.01282219\n",
      " 0.01282219 0.01282219 0.01282219]\n",
      "[0.         0.         0.         0.87818718 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.75637645 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.0128221  0.0128221  0.0128221  0.51276004 0.0128221  0.0128221\n",
      " 0.0128221  0.0128221  0.0128221  0.0128221  0.0128221  0.0128221\n",
      " 0.0128221  0.0128221  0.0128221  0.0128221  0.0128221  0.0128221\n",
      " 0.0128221  0.0128221  0.0128221  0.0128221  0.0128221  0.0128221\n",
      " 0.0128221  0.0128221  0.0128221  0.0128221  0.0128221  0.0128221\n",
      " 0.0128221  0.0128221  0.0128221  0.0128221  0.0128221  0.0128221\n",
      " 0.0128221  0.0128221  0.0128221 ]\n",
      "[0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.51281494 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066]\n",
      "[0.01282498 0.01282498 0.01282498 0.51265091 0.01282498 0.01282498\n",
      " 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498\n",
      " 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498\n",
      " 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498\n",
      " 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498\n",
      " 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498 0.01282498\n",
      " 0.01282498 0.01282498 0.01282498]\n",
      "[0.01282193 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193\n",
      " 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193\n",
      " 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193\n",
      " 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193 0.51276678\n",
      " 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193\n",
      " 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193 0.01282193\n",
      " 0.01282193 0.01282193 0.01282193]\n",
      "[0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.51281494 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066 0.01282066\n",
      " 0.01282066 0.01282066 0.01282066]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.01282063 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063\n",
      " 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063\n",
      " 0.01282063 0.51281619 0.01282063 0.01282063 0.01282063 0.01282063\n",
      " 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063\n",
      " 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063\n",
      " 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063 0.01282063\n",
      " 0.01282063 0.01282063 0.01282063]\n",
      "[0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      " 0.02564103 0.02564103 0.02564103]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75636917 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.01282144 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144\n",
      " 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144\n",
      " 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144\n",
      " 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144\n",
      " 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144 0.01282144\n",
      " 0.01282144 0.51278538 0.01282144 0.01282144 0.01282144 0.01282144\n",
      " 0.01282144 0.01282144 0.01282144]\n",
      "[0.01282124 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124\n",
      " 0.01282124 0.01282124 0.51279294 0.01282124 0.01282124 0.01282124\n",
      " 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124\n",
      " 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124\n",
      " 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124\n",
      " 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124 0.01282124\n",
      " 0.01282124 0.01282124 0.01282124]\n",
      "[0.01282123 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123\n",
      " 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123\n",
      " 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123\n",
      " 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123\n",
      " 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123 0.01282123\n",
      " 0.01282123 0.51279324 0.01282123 0.01282123 0.01282123 0.01282123\n",
      " 0.01282123 0.01282123 0.01282123]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.27562195 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.40809053 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.67519844 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.6750918 0.        0.        0.\n",
      " 0.        0.        0.        0.       ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.75639451 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.83759874 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.75637913 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.67519176 0.         0.         0.\n",
      " 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "for i in new_tmp[\"topic_distribution\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_text(text):\n",
    "  token_ls = word_tokenize(text,keep_whitespace=False,engine='attacut')\n",
    "  return token_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_distribution(lda_model, dataframe, dictionary, text_column, tokenize_func):\n",
    "        \"\"\"\n",
    "        Get topic distribution scores for each document in the DataFrame using the given LDA model.\n",
    "\n",
    "        Parameters:\n",
    "            lda_model (gensim.models.ldamodel.LdaModel): Gensim LDA model.\n",
    "            dataframe (pandas.DataFrame): DataFrame containing the text column.\n",
    "            text_column (str): Name of the text column in the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with an additional column containing topic distribution scores.\n",
    "        \"\"\"\n",
    "        topic_scores = []\n",
    "\n",
    "        # Initialize an empty list to store topic distribution scores for each document\n",
    "        for index, row in dataframe.iterrows():\n",
    "        # Convert the document text to bag-of-words representation using the dictionary\n",
    "            bow = dictionary.doc2bow(tokenize_func(row[text_column]))\n",
    "            \n",
    "            # Infer the topic distribution for the document using the LDA model\n",
    "            doc_topics = lda_model.get_document_topics(bow)\n",
    "            \n",
    "            # Extract the topic distribution scores from the result\n",
    "            scores = np.zeros(lda_model.num_topics)  # Initialize scores array\n",
    "            for topic, score in doc_topics:\n",
    "                scores[topic] = score\n",
    "            \n",
    "            # Append the topic scores to the list\n",
    "            topic_scores.append(scores)\n",
    "        \n",
    "        # Add the topic distribution scores as a new column in the DataFrame\n",
    "        dataframe['topic_distribution'] = topic_scores\n",
    "        \n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_asr():\n",
    "    result_dct = {  'filename':[],\n",
    "                    'model':[],\n",
    "                    'number_of_embedding_entry': [],\n",
    "                    'embedding_time': [],\n",
    "                    'embedding_time_per_entry': [],\n",
    "                    'mean_hit@10': [],\n",
    "                    'map@10': [],\n",
    "                    'mean_hit@5': [],\n",
    "                    'map@5': [],\n",
    "                    'mean_hit@3': [],\n",
    "                    'map@3': [],\n",
    "                    'mean_hit@1': [],\n",
    "                    'map@1': [],\n",
    "                }\n",
    "    evaluation = Evaluation()\n",
    "    data_filenames = [\"../../labeled/labeled_transcript_01.csv\", \"../../labeled/labeled_transcript_02.csv\", \"../../labeled/labeled_transcript_03.csv\", \"../../labeled/labeled_transcript_04.csv\"]\n",
    "    model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "    max_seq_length=128\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.max_seq_length = max_seq_length\n",
    "    for filename in data_filenames:\n",
    "        df = pd.read_csv(filename, index_col=0)\n",
    "        df = get_topic_distribution(lda_model, df, dictionary, \"text\", tokenize_func = tokenizer_text)\n",
    "        report = evaluation.get_st_report(df, model, lda_model, dictionary,tokenizer_func= tokenizer_text, k_list=[10, 5, 3, 1])\n",
    "        result_dct[\"filename\"].append(filename)\n",
    "        result_dct[\"model\"].append(model_name)\n",
    "        for key in report.keys():\n",
    "            result_dct[key].append(report[key])\n",
    "\n",
    "    final_df = pd.DataFrame(data = result_dct)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:23<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0321,  0.0883, -0.0169,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0651,  0.0155, -0.0116,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0315,  0.1314, -0.0146,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0730,  0.1064, -0.0138,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0132, -0.0535, -0.0112,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0053,  0.2759, -0.0181,  ...,  0.0256,  0.0256,  0.0256]],\n",
      "       dtype=torch.float64)\n",
      "Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49, 54, 48, 47, 51, 143, 100, 107, 130, 45], [51, 49, 54, 130, 44, 148, 131, 48, 52, 115], [130, 143, 41, 100, 119, 122, 80, 59, 42, 49], [115, 113, 63, 112, 130, 145, 64, 111, 117, 65], [54, 65, 64, 130, 133, 101, 61, 68, 63, 131], [17, 11, 16, 15, 49, 14, 42, 12, 30, 79], [17, 33, 49, 42, 113, 115, 130, 124, 11, 145], [47, 107, 54, 59, 64, 49, 122, 63, 51, 68], [80, 81, 42, 41, 120, 79, 124, 119, 113, 130], [54, 65, 130, 64, 133, 101, 68, 63, 154, 131]]\n",
      "[[49, 50, 51], [51, 52, 53, 54], [79, 80, 81], [117, 118, 119, 120, 121, 122, 123, 124, 125], [130, 131, 132, 133, 134], [11, 12, 13, 14], [27], [58], [82, 83, 84, 85, 86, 87, 88, 89, 90], [135, 136, 137, 138, 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:01<00:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49, 54, 48, 47, 51], [51, 49, 54, 130, 44], [130, 143, 41, 100, 119], [115, 113, 63, 112, 130], [54, 65, 64, 130, 133], [17, 11, 16, 15, 49], [17, 33, 49, 42, 113], [47, 107, 54, 59, 64], [80, 81, 42, 41, 120], [54, 65, 130, 64, 133]]\n",
      "[[49, 50, 51], [51, 52, 53, 54], [79, 80, 81], [117, 118, 119, 120, 121, 122, 123, 124, 125], [130, 131, 132, 133, 134], [11, 12, 13, 14], [27], [58], [82, 83, 84, 85, 86, 87, 88, 89, 90], [135, 136, 137, 138, 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107, 49, 143], [51, 49, 54], [130, 143, 41], [115, 113, 63], [54, 65, 64], [17, 11, 16], [17, 33, 49], [47, 107, 54], [80, 81, 42], [54, 65, 130]]\n",
      "[[49, 50, 51], [51, 52, 53, 54], [79, 80, 81], [117, 118, 119, 120, 121, 122, 123, 124, 125], [130, 131, 132, 133, 134], [11, 12, 13, 14], [27], [58], [82, 83, 84, 85, 86, 87, 88, 89, 90], [135, 136, 137, 138, 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49], [51], [130], [115], [54], [17], [17], [47], [80], [54]]\n",
      "[[49, 50, 51], [51, 52, 53, 54], [79, 80, 81], [117, 118, 119, 120, 121, 122, 123, 124, 125], [130, 131, 132, 133, 134], [11, 12, 13, 14], [27], [58], [82, 83, 84, 85, 86, 87, 88, 89, 90], [135, 136, 137, 138, 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  40%|████      | 2/5 [00:13<00:20,  6.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_report \u001b[38;5;241m=\u001b[39m \u001b[43meval_asr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[133], line 25\u001b[0m, in \u001b[0;36meval_asr\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     24\u001b[0m df \u001b[38;5;241m=\u001b[39m get_topic_distribution(lda_model, df, dictionary, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenize_func \u001b[38;5;241m=\u001b[39m tokenizer_text)\n\u001b[1;32m---> 25\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_st_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m result_dct[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(filename)\n\u001b[0;32m     27\u001b[0m result_dct[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_name)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\Desktop\\mcv-smart-learning-tools\\transcript_retrieval\\tests\\..\\evaluation\\evaluate_LDA2.py:101\u001b[0m, in \u001b[0;36mEvaluation.get_st_report\u001b[1;34m(self, labeled_df, model, lda_model, dictionary, tokenizer_func, edited_text, k_list)\u001b[0m\n\u001b[0;32m     98\u001b[0m     corpus_embeddings \u001b[38;5;241m=\u001b[39m labeled_df[TRANSCRIPT_COL]\n\u001b[0;32m    100\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 101\u001b[0m corpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# print(corpus_embeddings.shape)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:284\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    281\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 284\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    287\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:837\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    828\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    830\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    831\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    832\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    835\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    836\u001b[0m )\n\u001b[1;32m--> 837\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    850\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:525\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    514\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    515\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m         output_attentions,\n\u001b[0;32m    523\u001b[0m     )\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:414\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    404\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:341\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    333\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    340\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 341\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    351\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:220\u001b[0m, in \u001b[0;36mXLMRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    218\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m1\u001b[39m], value_layer], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    221\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states))\n\u001b[0;32m    223\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pacha\\miniconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_report = eval_asr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>number_of_embedding_entry</th>\n",
       "      <th>embedding_time</th>\n",
       "      <th>embedding_time_per_entry</th>\n",
       "      <th>mean_hit@10</th>\n",
       "      <th>map@10</th>\n",
       "      <th>mean_hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mean_hit@3</th>\n",
       "      <th>map@3</th>\n",
       "      <th>mean_hit@1</th>\n",
       "      <th>map@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../labeled/labeled_transcript_01.csv</td>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>158</td>\n",
       "      <td>22.967071</td>\n",
       "      <td>0.145361</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.226508</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../labeled/labeled_transcript_02.csv</td>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>154</td>\n",
       "      <td>21.989509</td>\n",
       "      <td>0.142789</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.432857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.406111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../labeled/labeled_transcript_03.csv</td>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>121</td>\n",
       "      <td>17.258912</td>\n",
       "      <td>0.142636</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.573452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../labeled/labeled_transcript_04.csv</td>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>221</td>\n",
       "      <td>35.443091</td>\n",
       "      <td>0.160376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472761</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.542778</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename  \\\n",
       "0  ../../labeled/labeled_transcript_01.csv   \n",
       "1  ../../labeled/labeled_transcript_02.csv   \n",
       "2  ../../labeled/labeled_transcript_03.csv   \n",
       "3  ../../labeled/labeled_transcript_04.csv   \n",
       "\n",
       "                                               model  \\\n",
       "0  sentence-transformers/paraphrase-multilingual-...   \n",
       "1  sentence-transformers/paraphrase-multilingual-...   \n",
       "2  sentence-transformers/paraphrase-multilingual-...   \n",
       "3  sentence-transformers/paraphrase-multilingual-...   \n",
       "\n",
       "   number_of_embedding_entry  embedding_time  embedding_time_per_entry  \\\n",
       "0                        158       22.967071                  0.145361   \n",
       "1                        154       21.989509                  0.142789   \n",
       "2                        121       17.258912                  0.142636   \n",
       "3                        221       35.443091                  0.160376   \n",
       "\n",
       "   mean_hit@10    map@10  mean_hit@5     map@5  mean_hit@3     map@3  \\\n",
       "0          0.6  0.226508         0.4  0.282500         0.3  0.233333   \n",
       "1          0.8  0.432857         0.5  0.406111         0.5  0.416667   \n",
       "2          0.8  0.573452         0.8  0.670000         0.7  0.683333   \n",
       "3          1.0  0.472761         0.9  0.542778         0.7  0.550000   \n",
       "\n",
       "   mean_hit@1  map@1  \n",
       "0         0.1    0.1  \n",
       "1         0.4    0.4  \n",
       "2         0.7    0.7  \n",
       "3         0.4    0.4  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report.to_csv(\"LDA_feature.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
